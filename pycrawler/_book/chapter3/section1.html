<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>1. Python爬虫利器一之Requests库的用法 | Python爬虫学习系列教程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../chapter3/section2.html" />
    
    
    <link rel="prev" href="../chapter3/index.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="3.1"
        data-chapter-title="1. Python爬虫利器一之Requests库的用法"
        data-filepath="chapter3/section1.md"
        data-basepath=".."
        data-revision="Wed Jun 21 2017 19:16:14 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Python爬虫学习系列教程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="chapter1/index.html">
            
                
                    <a href="../chapter1/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        一、爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="chapter1/section1.html">
            
                
                    <a href="../chapter1/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        1. Python爬虫入门一之综述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="chapter1/section2.html">
            
                
                    <a href="../chapter1/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        2. Python爬虫入门二之爬虫基础了解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="chapter1/section3.html">
            
                
                    <a href="../chapter1/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        3. Python爬虫入门三之Urllib库的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="chapter1/section4.html">
            
                
                    <a href="../chapter1/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        4. Python爬虫入门四之Urllib库的高级用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="chapter1/section5.html">
            
                
                    <a href="../chapter1/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.5.</b>
                        
                        5. Python爬虫入门五之URLError异常处理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="chapter1/section6.html">
            
                
                    <a href="../chapter1/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.6.</b>
                        
                        6. Python爬虫入门六之Cookie的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="chapter1/section7.html">
            
                
                    <a href="../chapter1/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.7.</b>
                        
                        7. Python爬虫入门七之正则表达式
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="chapter2/index.html">
            
                
                    <a href="../chapter2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        二、爬虫实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="chapter2/section1.html">
            
                
                    <a href="../chapter2/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        1. Python爬虫实战一之爬取糗事百科段子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="chapter2/section2.html">
            
                
                    <a href="../chapter2/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        2. Python爬虫实战二之爬取百度贴吧帖子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="chapter2/section3.html">
            
                
                    <a href="../chapter2/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        3. Python爬虫实战三之实现山东大学无线网络掉线自动重连
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="chapter2/section4.html">
            
                
                    <a href="../chapter2/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        4. Python爬虫实战四之抓取淘宝MM照片
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="chapter2/section5.html">
            
                
                    <a href="../chapter2/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        5. Python爬虫实战五之模拟登录淘宝并获取所有订单
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="chapter2/section6.html">
            
                
                    <a href="../chapter2/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        6. Python爬虫实战六之抓取爱问知识人问题并保存至数据库
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="chapter2/section7.html">
            
                
                    <a href="../chapter2/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.</b>
                        
                        7. Python爬虫实战七之计算大学本学期绩点
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="chapter2/section8.html">
            
                
                    <a href="../chapter2/section8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.8.</b>
                        
                        8. Python爬虫实战八之利用Selenium抓取淘宝匿名旺旺
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="chapter3/index.html">
            
                
                    <a href="../chapter3/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        三、爬虫利器
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="3.1" data-path="chapter3/section1.html">
            
                
                    <a href="../chapter3/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        1. Python爬虫利器一之Requests库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="chapter3/section2.html">
            
                
                    <a href="../chapter3/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        2. Python爬虫利器二之Beautiful Soup的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="chapter3/section3.html">
            
                
                    <a href="../chapter3/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        3. Python爬虫利器三之Xpath语法与lxml库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="chapter3/section4.html">
            
                
                    <a href="../chapter3/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        4. Python爬虫利器四之PhantomJS的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="chapter3/section5.html">
            
                
                    <a href="../chapter3/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        5. Python爬虫利器五之Selenium的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="chapter3/section6.html">
            
                
                    <a href="../chapter3/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.6.</b>
                        
                        6. Python爬虫利器六之PyQuery的用法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="chapter4/index.html">
            
                
                    <a href="../chapter4/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        四、爬虫进阶
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="chapter4/section1.html">
            
                
                    <a href="../chapter4/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        1. Python爬虫进阶一之爬虫框架概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter4/section2.html">
            
                
                    <a href="../chapter4/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        2. Python爬虫进阶二之PySpider框架安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="chapter4/section3.html">
            
                
                    <a href="../chapter4/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        3. Python爬虫进阶三之爬虫框架Scrapy安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="chapter4/section4.html">
            
                
                    <a href="../chapter4/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        4. Python爬虫进阶四之PySpider的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="chapter4/section5.html">
            
                
                    <a href="../chapter4/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        5. Python爬虫进阶五之多线程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="chapter4/section6.html">
            
                
                    <a href="../chapter4/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.6.</b>
                        
                        6. Python爬虫进阶六之多进程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="chapter4/section7.html">
            
                
                    <a href="../chapter4/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.7.</b>
                        
                        7. Python爬虫进阶七之设置ADSL拨号服务器代理
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Python爬虫学习系列教程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="python&#x722C;&#x866B;&#x5229;&#x5668;&#x4E00;&#x4E4B;requests&#x5E93;&#x7684;&#x7528;&#x6CD5;">Python&#x722C;&#x866B;&#x5229;&#x5668;&#x4E00;&#x4E4B;Requests&#x5E93;&#x7684;&#x7528;&#x6CD5;</h1>
<h2 id="&#x524D;&#x8A00;">&#x524D;&#x8A00;</h2>
<p>&#x4E4B;&#x524D;&#x6211;&#x4EEC;&#x7528;&#x4E86; urllib &#x5E93;&#xFF0C;&#x8FD9;&#x4E2A;&#x4F5C;&#x4E3A;&#x5165;&#x95E8;&#x7684;&#x5DE5;&#x5177;&#x8FD8;&#x662F;&#x4E0D;&#x9519;&#x7684;&#xFF0C;&#x5BF9;&#x4E86;&#x89E3;&#x4E00;&#x4E9B;&#x722C;&#x866B;&#x7684;&#x57FA;&#x672C;&#x7406;&#x5FF5;&#xFF0C;&#x638C;&#x63E1;&#x722C;&#x866B;&#x722C;&#x53D6;&#x7684;&#x6D41;&#x7A0B;&#x6709;&#x6240;&#x5E2E;&#x52A9;&#x3002;&#x5165;&#x95E8;&#x4E4B;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x5C31;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x4E00;&#x4E9B;&#x66F4;&#x52A0;&#x9AD8;&#x7EA7;&#x7684;&#x5185;&#x5BB9;&#x548C;&#x5DE5;&#x5177;&#x6765;&#x65B9;&#x4FBF;&#x6211;&#x4EEC;&#x7684;&#x722C;&#x53D6;&#x3002;&#x90A3;&#x4E48;&#x8FD9;&#x4E00;&#x8282;&#x6765;&#x7B80;&#x5355;&#x4ECB;&#x7ECD;&#x4E00;&#x4E0B; requests &#x5E93;&#x7684;&#x57FA;&#x672C;&#x7528;&#x6CD5;&#x3002;</p>
<p>&#x6CE8;&#xFF1A;Python &#x7248;&#x672C;&#x4F9D;&#x7136;&#x57FA;&#x4E8E; 2.7</p>
<h2 id="&#x5B98;&#x65B9;&#x6587;&#x6863;">&#x5B98;&#x65B9;&#x6587;&#x6863;</h2>
<p>&#x4EE5;&#x4E0B;&#x5185;&#x5BB9;&#x5927;&#x591A;&#x6765;&#x81EA;&#x4E8E;&#x5B98;&#x65B9;&#x6587;&#x6863;&#xFF0C;&#x672C;&#x6587;&#x8FDB;&#x884C;&#x4E86;&#x4E00;&#x4E9B;&#x4FEE;&#x6539;&#x548C;&#x603B;&#x7ED3;&#x3002;&#x8981;&#x4E86;&#x89E3;&#x66F4;&#x591A;&#x53EF;&#x4EE5;&#x53C2;&#x8003;<a href="http://docs.python-requests.org/en/master/" target="_blank">&#x5B98;&#x65B9;&#x6587;&#x6863;</a></p>
<h2 id="&#x5B89;&#x88C5;">&#x5B89;&#x88C5;</h2>
<p>&#x5229;&#x7528; pip &#x5B89;&#x88C5;</p>
<pre><code>$ pip install requests
</code></pre><p>&#x6216;&#x8005;&#x5229;&#x7528; easy_install</p>
<pre><code>$ easy_install requests
</code></pre><p>&#x901A;&#x8FC7;&#x4EE5;&#x4E0A;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#x5747;&#x53EF;&#x4EE5;&#x5B8C;&#x6210;&#x5B89;&#x88C5;&#x3002;</p>
<h2 id="&#x5F15;&#x5165;">&#x5F15;&#x5165;</h2>
<p>&#x9996;&#x5148;&#x6211;&#x4EEC;&#x5F15;&#x5165;&#x4E00;&#x4E2A;&#x5C0F;&#x4F8B;&#x5B50;&#x6765;&#x611F;&#x53D7;&#x4E00;&#x4E0B;</p>
<pre><code>import requests

r = requests.get(&apos;http://cuiqingcai.com&apos;)
print type(r)
print r.status_code
print r.encoding
#print r.text
print r.cookies
</code></pre><p>&#x4EE5;&#x4E0A;&#x4EE3;&#x7801;&#x6211;&#x4EEC;&#x8BF7;&#x6C42;&#x4E86;&#x672C;&#x7AD9;&#x70B9;&#x7684;&#x7F51;&#x5740;&#xFF0C;&#x7136;&#x540E;&#x6253;&#x5370;&#x51FA;&#x4E86;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x72B6;&#x6001;&#x7801;&#xFF0C;&#x7F16;&#x7801;&#x65B9;&#x5F0F;&#xFF0C;Cookies&#x7B49;&#x5185;&#x5BB9;&#x3002;</p>
<p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;&#x5982;&#x4E0B;</p>
<pre><code>&lt;class &apos;requests.models.Response&apos;&gt;
200
UTF-8
&lt;RequestsCookieJar[]&gt;
</code></pre><p>&#x600E;&#x6837;&#xFF0C;&#x662F;&#x4E0D;&#x662F;&#x5F88;&#x65B9;&#x4FBF;&#x3002;&#x522B;&#x6025;&#xFF0C;&#x66F4;&#x65B9;&#x4FBF;&#x7684;&#x5728;&#x540E;&#x9762;&#x5462;&#x3002;</p>
<h2 id="&#x57FA;&#x672C;&#x8BF7;&#x6C42;">&#x57FA;&#x672C;&#x8BF7;&#x6C42;</h2>
<p>requests&#x5E93;&#x63D0;&#x4F9B;&#x4E86;http&#x6240;&#x6709;&#x7684;&#x57FA;&#x672C;&#x8BF7;&#x6C42;&#x65B9;&#x5F0F;&#x3002;&#x4F8B;&#x5982;</p>
<pre><code>r = requests.post(&quot;http://httpbin.org/post&quot;)
r = requests.put(&quot;http://httpbin.org/put&quot;)
r = requests.delete(&quot;http://httpbin.org/delete&quot;)
r = requests.head(&quot;http://httpbin.org/get&quot;)
r = requests.options(&quot;http://httpbin.org/get&quot;)
</code></pre><p>&#x55EF;&#xFF0C;&#x4E00;&#x53E5;&#x8BDD;&#x641E;&#x5B9A;&#x3002;</p>
<h2 id="&#x57FA;&#x672C;get&#x8BF7;&#x6C42;">&#x57FA;&#x672C;GET&#x8BF7;&#x6C42;</h2>
<p>&#x6700;&#x57FA;&#x672C;&#x7684;GET&#x8BF7;&#x6C42;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x7528;get&#x65B9;&#x6CD5;</p>
<pre><code>r = requests.get(&quot;http://httpbin.org/get&quot;)
</code></pre><p>&#x5982;&#x679C;&#x60F3;&#x8981;&#x52A0;&#x53C2;&#x6570;&#xFF0C;&#x53EF;&#x4EE5;&#x5229;&#x7528; params &#x53C2;&#x6570;</p>
<pre><code>import requests

payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;}
r = requests.get(&quot;http://httpbin.org/get&quot;, params=payload)
print r.url
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>http://httpbin.org/get?key2=value2&amp;key1=value1
</code></pre><p>&#x5982;&#x679C;&#x60F3;&#x8BF7;&#x6C42;JSON&#x6587;&#x4EF6;&#xFF0C;&#x53EF;&#x4EE5;&#x5229;&#x7528; json() &#x65B9;&#x6CD5;&#x89E3;&#x6790;</p>
<p>&#x4F8B;&#x5982;&#x81EA;&#x5DF1;&#x5199;&#x4E00;&#x4E2A;JSON&#x6587;&#x4EF6;&#x547D;&#x540D;&#x4E3A;a.json&#xFF0C;&#x5185;&#x5BB9;&#x5982;&#x4E0B;</p>
<pre><code>[&quot;foo&quot;, &quot;bar&quot;, {
  &quot;foo&quot;: &quot;bar&quot;
}]
</code></pre><p>&#x5229;&#x7528;&#x5982;&#x4E0B;&#x7A0B;&#x5E8F;&#x8BF7;&#x6C42;&#x5E76;&#x89E3;&#x6790;</p>
<pre><code>import requests

r = requests.get(&quot;a.json&quot;)
print r.text
print r.json()
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;&#x5982;&#x4E0B;&#xFF0C;&#x5176;&#x4E2D;&#x4E00;&#x4E2A;&#x662F;&#x76F4;&#x63A5;&#x8F93;&#x51FA;&#x5185;&#x5BB9;&#xFF0C;&#x53E6;&#x5916;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#x662F;&#x5229;&#x7528; json() &#x65B9;&#x6CD5;&#x89E3;&#x6790;&#xFF0C;&#x611F;&#x53D7;&#x4E0B;&#x5B83;&#x4EEC;&#x7684;&#x4E0D;&#x540C;</p>
<pre><code>[&quot;foo&quot;, &quot;bar&quot;, {
 &quot;foo&quot;: &quot;bar&quot;
 }]
 [u&apos;foo&apos;, u&apos;bar&apos;, {u&apos;foo&apos;: u&apos;bar&apos;}]
</code></pre><p>&#x5982;&#x679C;&#x60F3;&#x83B7;&#x53D6;&#x6765;&#x81EA;&#x670D;&#x52A1;&#x5668;&#x7684;&#x539F;&#x59CB;&#x5957;&#x63A5;&#x5B57;&#x54CD;&#x5E94;&#xFF0C;&#x53EF;&#x4EE5;&#x53D6;&#x5F97; r.raw &#x3002; &#x4E0D;&#x8FC7;&#x9700;&#x8981;&#x5728;&#x521D;&#x59CB;&#x8BF7;&#x6C42;&#x4E2D;&#x8BBE;&#x7F6E; stream=True &#x3002;</p>
<pre><code>r = requests.get(&apos;https://github.com/timeline.json&apos;, stream=True)
r.raw
&lt;requests.packages.urllib3.response.HTTPResponse object at 0x101194810&gt;
r.raw.read(10)
&apos;\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03&apos;
</code></pre><p>&#x8FD9;&#x6837;&#x5C31;&#x83B7;&#x53D6;&#x4E86;&#x7F51;&#x9875;&#x539F;&#x59CB;&#x5957;&#x63A5;&#x5B57;&#x5185;&#x5BB9;&#x3002;</p>
<p>&#x5982;&#x679C;&#x60F3;&#x6DFB;&#x52A0; headers&#xFF0C;&#x53EF;&#x4EE5;&#x4F20; headers &#x53C2;&#x6570;</p>
<pre><code>import requests

payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;}
headers = {&apos;content-type&apos;: &apos;application/json&apos;}
r = requests.get(&quot;http://httpbin.org/get&quot;, params=payload, headers=headers)
print r.url
</code></pre><p>&#x901A;&#x8FC7;headers&#x53C2;&#x6570;&#x53EF;&#x4EE5;&#x589E;&#x52A0;&#x8BF7;&#x6C42;&#x5934;&#x4E2D;&#x7684;headers&#x4FE1;&#x606F;</p>
<h2 id="&#x57FA;&#x672C;post&#x8BF7;&#x6C42;">&#x57FA;&#x672C;POST&#x8BF7;&#x6C42;</h2>
<p>&#x5BF9;&#x4E8E; POST &#x8BF7;&#x6C42;&#x6765;&#x8BF4;&#xFF0C;&#x6211;&#x4EEC;&#x4E00;&#x822C;&#x9700;&#x8981;&#x4E3A;&#x5B83;&#x589E;&#x52A0;&#x4E00;&#x4E9B;&#x53C2;&#x6570;&#x3002;&#x90A3;&#x4E48;&#x6700;&#x57FA;&#x672C;&#x7684;&#x4F20;&#x53C2;&#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x5229;&#x7528; data &#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x3002;</p>
<pre><code>import requests

payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;}
r = requests.post(&quot;http://httpbin.org/post&quot;, data=payload)
print r.text
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>{
  &quot;args&quot;: {}, 
  &quot;data&quot;: &quot;&quot;, 
  &quot;files&quot;: {}, 
  &quot;form&quot;: {
    &quot;key1&quot;: &quot;value1&quot;, 
    &quot;key2&quot;: &quot;value2&quot;
  }, 
  &quot;headers&quot;: {
    &quot;Accept&quot;: &quot;*/*&quot;, 
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
    &quot;Content-Length&quot;: &quot;23&quot;, 
    &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, 
    &quot;Host&quot;: &quot;httpbin.org&quot;, 
    &quot;User-Agent&quot;: &quot;python-requests/2.9.1&quot;
  }, 
  &quot;json&quot;: null, 
  &quot;url&quot;: &quot;http://httpbin.org/post&quot;
}
</code></pre><p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x53C2;&#x6570;&#x4F20;&#x6210;&#x529F;&#x4E86;&#xFF0C;&#x7136;&#x540E;&#x670D;&#x52A1;&#x5668;&#x8FD4;&#x56DE;&#x4E86;&#x6211;&#x4EEC;&#x4F20;&#x7684;&#x6570;&#x636E;&#x3002;</p>
<p>&#x6709;&#x65F6;&#x5019;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x4F20;&#x9001;&#x7684;&#x4FE1;&#x606F;&#x4E0D;&#x662F;&#x8868;&#x5355;&#x5F62;&#x5F0F;&#x7684;&#xFF0C;&#x9700;&#x8981;&#x6211;&#x4EEC;&#x4F20;JSON&#x683C;&#x5F0F;&#x7684;&#x6570;&#x636E;&#x8FC7;&#x53BB;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x7528; json.dumps() &#x65B9;&#x6CD5;&#x628A;&#x8868;&#x5355;&#x6570;&#x636E;&#x5E8F;&#x5217;&#x5316;&#x3002;</p>
<pre><code>import json
import requests

url = &apos;http://httpbin.org/post&apos;
payload = {&apos;some&apos;: &apos;data&apos;}
r = requests.post(url, data=json.dumps(payload))
print r.text
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>{
  &quot;args&quot;: {}, 
  &quot;data&quot;: &quot;{\&quot;some\&quot;: \&quot;data\&quot;}&quot;, 
  &quot;files&quot;: {}, 
  &quot;form&quot;: {}, 
  &quot;headers&quot;: {
    &quot;Accept&quot;: &quot;*/*&quot;, 
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
    &quot;Content-Length&quot;: &quot;16&quot;, 
    &quot;Host&quot;: &quot;httpbin.org&quot;, 
    &quot;User-Agent&quot;: &quot;python-requests/2.9.1&quot;
  }, 
  &quot;json&quot;: {
    &quot;some&quot;: &quot;data&quot;
  },  
  &quot;url&quot;: &quot;http://httpbin.org/post&quot;
}
</code></pre><p>&#x901A;&#x8FC7;&#x4E0A;&#x8FF0;&#x65B9;&#x6CD5;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;POST JSON&#x683C;&#x5F0F;&#x7684;&#x6570;&#x636E;</p>
<p>&#x5982;&#x679C;&#x60F3;&#x8981;&#x4E0A;&#x4F20;&#x6587;&#x4EF6;&#xFF0C;&#x90A3;&#x4E48;&#x76F4;&#x63A5;&#x7528; file &#x53C2;&#x6570;&#x5373;&#x53EF;</p>
<p>&#x65B0;&#x5EFA;&#x4E00;&#x4E2A; a.txt &#x7684;&#x6587;&#x4EF6;&#xFF0C;&#x5185;&#x5BB9;&#x5199;&#x4E0A; Hello World!</p>
<pre><code>import requests

url = &apos;http://httpbin.org/post&apos;
files = {&apos;file&apos;: open(&apos;test.txt&apos;, &apos;rb&apos;)}
r = requests.post(url, files=files)
print r.text
</code></pre><p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x8FD0;&#x884C;&#x7ED3;&#x679C;&#x5982;&#x4E0B;</p>
<pre><code>{
  &quot;args&quot;: {}, 
  &quot;data&quot;: &quot;&quot;, 
  &quot;files&quot;: {
    &quot;file&quot;: &quot;Hello World!&quot;
  }, 
  &quot;form&quot;: {}, 
  &quot;headers&quot;: {
    &quot;Accept&quot;: &quot;*/*&quot;, 
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
    &quot;Content-Length&quot;: &quot;156&quot;, 
    &quot;Content-Type&quot;: &quot;multipart/form-data; boundary=7d8eb5ff99a04c11bb3e862ce78d7000&quot;, 
    &quot;Host&quot;: &quot;httpbin.org&quot;, 
    &quot;User-Agent&quot;: &quot;python-requests/2.9.1&quot;
  }, 
  &quot;json&quot;: null, 
  &quot;url&quot;: &quot;http://httpbin.org/post&quot;
}
</code></pre><p>&#x8FD9;&#x6837;&#x6211;&#x4EEC;&#x4FBF;&#x6210;&#x529F;&#x5B8C;&#x6210;&#x4E86;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x7684;&#x4E0A;&#x4F20;&#x3002;</p>
<p>requests &#x662F;&#x652F;&#x6301;&#x6D41;&#x5F0F;&#x4E0A;&#x4F20;&#x7684;&#xFF0C;&#x8FD9;&#x5141;&#x8BB8;&#x4F60;&#x53D1;&#x9001;&#x5927;&#x7684;&#x6570;&#x636E;&#x6D41;&#x6216;&#x6587;&#x4EF6;&#x800C;&#x65E0;&#x9700;&#x5148;&#x628A;&#x5B83;&#x4EEC;&#x8BFB;&#x5165;&#x5185;&#x5B58;&#x3002;&#x8981;&#x4F7F;&#x7528;&#x6D41;&#x5F0F;&#x4E0A;&#x4F20;&#xFF0C;&#x4EC5;&#x9700;&#x4E3A;&#x4F60;&#x7684;&#x8BF7;&#x6C42;&#x4F53;&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;&#x7C7B;&#x6587;&#x4EF6;&#x5BF9;&#x8C61;&#x5373;&#x53EF;</p>
<pre><code>with open(&apos;massive-body&apos;) as f:
    requests.post(&apos;http://some.url/streamed&apos;, data=f)
</code></pre><p>&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x975E;&#x5E38;&#x5B9E;&#x7528;&#x65B9;&#x4FBF;&#x7684;&#x529F;&#x80FD;&#x3002;</p>
<h2 id="cookies">Cookies</h2>
<p>&#x5982;&#x679C;&#x4E00;&#x4E2A;&#x54CD;&#x5E94;&#x4E2D;&#x5305;&#x542B;&#x4E86;cookie&#xFF0C;&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5229;&#x7528; cookies &#x53D8;&#x91CF;&#x6765;&#x62FF;&#x5230;</p>
<pre><code>import requests

url = &apos;http://example.com&apos;
r = requests.get(url)
print r.cookies
print r.cookies[&apos;example_cookie_name&apos;]
</code></pre><p>&#x4EE5;&#x4E0A;&#x7A0B;&#x5E8F;&#x4EC5;&#x662F;&#x6837;&#x4F8B;&#xFF0C;&#x53EF;&#x4EE5;&#x7528; cookies &#x53D8;&#x91CF;&#x6765;&#x5F97;&#x5230;&#x7AD9;&#x70B9;&#x7684; cookies</p>
<p>&#x53E6;&#x5916;&#x53EF;&#x4EE5;&#x5229;&#x7528; cookies &#x53D8;&#x91CF;&#x6765;&#x5411;&#x670D;&#x52A1;&#x5668;&#x53D1;&#x9001; cookies &#x4FE1;&#x606F;</p>
<pre><code>import requests

url = &apos;http://httpbin.org/cookies&apos;
cookies = dict(cookies_are=&apos;working&apos;)
r = requests.get(url, cookies=cookies)
print r.text
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>&apos;{&quot;cookies&quot;: {&quot;cookies_are&quot;: &quot;working&quot;}}&apos;
</code></pre><p>&#x53EF;&#x4EE5;&#x5DF2;&#x7ECF;&#x6210;&#x529F;&#x5411;&#x670D;&#x52A1;&#x5668;&#x53D1;&#x9001;&#x4E86; cookies</p>
<h2 id="&#x8D85;&#x65F6;&#x914D;&#x7F6E;">&#x8D85;&#x65F6;&#x914D;&#x7F6E;</h2>
<p>&#x53EF;&#x4EE5;&#x5229;&#x7528; timeout &#x53D8;&#x91CF;&#x6765;&#x914D;&#x7F6E;&#x6700;&#x5927;&#x8BF7;&#x6C42;&#x65F6;&#x95F4;</p>
<pre><code>requests.get(&apos;http://github.com&apos;, timeout=0.001)
</code></pre><p>&#x6CE8;&#xFF1A;timeout &#x4EC5;&#x5BF9;&#x8FDE;&#x63A5;&#x8FC7;&#x7A0B;&#x6709;&#x6548;&#xFF0C;&#x4E0E;&#x54CD;&#x5E94;&#x4F53;&#x7684;&#x4E0B;&#x8F7D;&#x65E0;&#x5173;&#x3002;</p>
<p>&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x8FD9;&#x4E2A;&#x65F6;&#x95F4;&#x53EA;&#x9650;&#x5236;&#x8BF7;&#x6C42;&#x7684;&#x65F6;&#x95F4;&#x3002;&#x5373;&#x4F7F;&#x8FD4;&#x56DE;&#x7684; response &#x5305;&#x542B;&#x5F88;&#x5927;&#x5185;&#x5BB9;&#xFF0C;&#x4E0B;&#x8F7D;&#x9700;&#x8981;&#x4E00;&#x5B9A;&#x65F6;&#x95F4;&#xFF0C;&#x7136;&#x800C;&#x8FD9;&#x5E76;&#x6CA1;&#x6709;&#x4EC0;&#x4E48;&#x5375;&#x7528;&#x3002;</p>
<h2 id="&#x4F1A;&#x8BDD;&#x5BF9;&#x8C61;">&#x4F1A;&#x8BDD;&#x5BF9;&#x8C61;</h2>
<p>&#x5728;&#x4EE5;&#x4E0A;&#x7684;&#x8BF7;&#x6C42;&#x4E2D;&#xFF0C;&#x6BCF;&#x6B21;&#x8BF7;&#x6C42;&#x5176;&#x5B9E;&#x90FD;&#x76F8;&#x5F53;&#x4E8E;&#x53D1;&#x8D77;&#x4E86;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x76F8;&#x5F53;&#x4E8E;&#x6211;&#x4EEC;&#x6BCF;&#x4E2A;&#x8BF7;&#x6C42;&#x90FD;&#x7528;&#x4E86;&#x4E0D;&#x540C;&#x7684;&#x6D4F;&#x89C8;&#x5668;&#x5355;&#x72EC;&#x6253;&#x5F00;&#x7684;&#x6548;&#x679C;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x5B83;&#x5E76;&#x4E0D;&#x662F;&#x6307;&#x7684;&#x4E00;&#x4E2A;&#x4F1A;&#x8BDD;&#xFF0C;&#x5373;&#x4F7F;&#x8BF7;&#x6C42;&#x7684;&#x662F;&#x540C;&#x4E00;&#x4E2A;&#x7F51;&#x5740;&#x3002;&#x6BD4;&#x5982;</p>
<pre><code>import requests

requests.get(&apos;http://httpbin.org/cookies/set/sessioncookie/123456789&apos;)
r = requests.get(&quot;http://httpbin.org/cookies&quot;)
print(r.text)
</code></pre><p>&#x7ED3;&#x679C;&#x662F;</p>
<pre><code>{
  &quot;cookies&quot;: {}
}
</code></pre><p>&#x5F88;&#x660E;&#x663E;&#xFF0C;&#x8FD9;&#x4E0D;&#x5728;&#x4E00;&#x4E2A;&#x4F1A;&#x8BDD;&#x4E2D;&#xFF0C;&#x65E0;&#x6CD5;&#x83B7;&#x53D6; cookies&#xFF0C;&#x90A3;&#x4E48;&#x5728;&#x4E00;&#x4E9B;&#x7AD9;&#x70B9;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x4FDD;&#x6301;&#x4E00;&#x4E2A;&#x6301;&#x4E45;&#x7684;&#x4F1A;&#x8BDD;&#x600E;&#x4E48;&#x529E;&#x5462;&#xFF1F;&#x5C31;&#x50CF;&#x7528;&#x4E00;&#x4E2A;&#x6D4F;&#x89C8;&#x5668;&#x901B;&#x6DD8;&#x5B9D;&#x4E00;&#x6837;&#xFF0C;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x9009;&#x9879;&#x5361;&#x4E4B;&#x95F4;&#x8DF3;&#x8F6C;&#xFF0C;&#x8FD9;&#x6837;&#x5176;&#x5B9E;&#x5C31;&#x662F;&#x5EFA;&#x7ACB;&#x4E86;&#x4E00;&#x4E2A;&#x957F;&#x4E45;&#x4F1A;&#x8BDD;&#x3002;</p>
<p>&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x5982;&#x4E0B;</p>
<pre><code>import requests

s = requests.Session()
s.get(&apos;http://httpbin.org/cookies/set/sessioncookie/123456789&apos;)
r = s.get(&quot;http://httpbin.org/cookies&quot;)
print(r.text)
</code></pre><p>&#x5728;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x8BF7;&#x6C42;&#x4E86;&#x4E24;&#x6B21;&#xFF0C;&#x4E00;&#x6B21;&#x662F;&#x8BBE;&#x7F6E; cookies&#xFF0C;&#x4E00;&#x6B21;&#x662F;&#x83B7;&#x5F97; cookies</p>
<p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>{
  &quot;cookies&quot;: {
    &quot;sessioncookie&quot;: &quot;123456789&quot;
  }
}
</code></pre><p>&#x53D1;&#x73B0;&#x53EF;&#x4EE5;&#x6210;&#x529F;&#x83B7;&#x53D6;&#x5230; cookies &#x4E86;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;&#x5EFA;&#x7ACB;&#x4E00;&#x4E2A;&#x4F1A;&#x8BDD;&#x5230;&#x4F5C;&#x7528;&#x3002;&#x4F53;&#x4F1A;&#x4E00;&#x4E0B;&#x3002;</p>
<p>&#x90A3;&#x4E48;&#x65E2;&#x7136;&#x4F1A;&#x8BDD;&#x662F;&#x4E00;&#x4E2A;&#x5168;&#x5C40;&#x7684;&#x53D8;&#x91CF;&#xFF0C;&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x80AF;&#x5B9A;&#x53EF;&#x4EE5;&#x7528;&#x6765;&#x5168;&#x5C40;&#x7684;&#x914D;&#x7F6E;&#x4E86;&#x3002;</p>
<pre><code>import requests

s = requests.Session()
s.headers.update({&apos;x-test&apos;: &apos;true&apos;})
r = s.get(&apos;http://httpbin.org/headers&apos;, headers={&apos;x-test2&apos;: &apos;true&apos;})
print r.text
</code></pre><p>&#x901A;&#x8FC7; s.headers.update &#x65B9;&#x6CD5;&#x8BBE;&#x7F6E;&#x4E86; headers &#x7684;&#x53D8;&#x91CF;&#x3002;&#x7136;&#x540E;&#x6211;&#x4EEC;&#x53C8;&#x5728;&#x8BF7;&#x6C42;&#x4E2D;&#x8BBE;&#x7F6E;&#x4E86;&#x4E00;&#x4E2A; headers&#xFF0C;&#x90A3;&#x4E48;&#x4F1A;&#x51FA;&#x73B0;&#x4EC0;&#x4E48;&#x7ED3;&#x679C;&#xFF1F;</p>
<p>&#x5F88;&#x7B80;&#x5355;&#xFF0C;&#x4E24;&#x4E2A;&#x53D8;&#x91CF;&#x90FD;&#x4F20;&#x9001;&#x8FC7;&#x53BB;&#x4E86;&#x3002;</p>
<p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>{
  &quot;headers&quot;: {
    &quot;Accept&quot;: &quot;*/*&quot;, 
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
    &quot;Host&quot;: &quot;httpbin.org&quot;, 
    &quot;User-Agent&quot;: &quot;python-requests/2.9.1&quot;, 
    &quot;X-Test&quot;: &quot;true&quot;, 
    &quot;X-Test2&quot;: &quot;true&quot;
  }
}
</code></pre><p>&#x5982;&#x679C;get&#x65B9;&#x6CD5;&#x4F20;&#x7684;headers &#x540C;&#x6837;&#x4E5F;&#x662F; x-test &#x5462;&#xFF1F;</p>
<pre><code>r = s.get(&apos;http://httpbin.org/headers&apos;, headers={&apos;x-test&apos;: &apos;true&apos;})
</code></pre><p>&#x55EF;&#xFF0C;&#x5B83;&#x4F1A;&#x8986;&#x76D6;&#x6389;&#x5168;&#x5C40;&#x7684;&#x914D;&#x7F6E;</p>
<pre><code>{
  &quot;headers&quot;: {
    &quot;Accept&quot;: &quot;*/*&quot;, 
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
    &quot;Host&quot;: &quot;httpbin.org&quot;, 
    &quot;User-Agent&quot;: &quot;python-requests/2.9.1&quot;, 
    &quot;X-Test&quot;: &quot;true&quot;
  }
}
</code></pre><p>&#x90A3;&#x5982;&#x679C;&#x4E0D;&#x60F3;&#x8981;&#x5168;&#x5C40;&#x914D;&#x7F6E;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x53D8;&#x91CF;&#x4E86;&#x5462;&#xFF1F;&#x5F88;&#x7B80;&#x5355;&#xFF0C;&#x8BBE;&#x7F6E;&#x4E3A; None &#x5373;&#x53EF;</p>
<pre><code>r = s.get(&apos;http://httpbin.org/headers&apos;, headers={&apos;x-test&apos;: None})
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>{
  &quot;headers&quot;: {
    &quot;Accept&quot;: &quot;*/*&quot;, 
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
    &quot;Host&quot;: &quot;httpbin.org&quot;, 
    &quot;User-Agent&quot;: &quot;python-requests/2.9.1&quot;
  }
}
</code></pre><p>&#x55EF;&#xFF0C;&#x4EE5;&#x4E0A;&#x5C31;&#x662F; session &#x4F1A;&#x8BDD;&#x7684;&#x57FA;&#x672C;&#x7528;&#x6CD5;</p>
<h2 id="ssl&#x8BC1;&#x4E66;&#x9A8C;&#x8BC1;">SSL&#x8BC1;&#x4E66;&#x9A8C;&#x8BC1;</h2>
<p>&#x73B0;&#x5728;&#x968F;&#x5904;&#x53EF;&#x89C1; https &#x5F00;&#x5934;&#x7684;&#x7F51;&#x7AD9;&#xFF0C;Requests&#x53EF;&#x4EE5;&#x4E3A;HTTPS&#x8BF7;&#x6C42;&#x9A8C;&#x8BC1;SSL&#x8BC1;&#x4E66;&#xFF0C;&#x5C31;&#x50CF;web&#x6D4F;&#x89C8;&#x5668;&#x4E00;&#x6837;&#x3002;&#x8981;&#x60F3;&#x68C0;&#x67E5;&#x67D0;&#x4E2A;&#x4E3B;&#x673A;&#x7684;SSL&#x8BC1;&#x4E66;&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; verify &#x53C2;&#x6570;</p>
<p>&#x73B0;&#x5728; 12306 &#x8BC1;&#x4E66;&#x4E0D;&#x662F;&#x65E0;&#x6548;&#x7684;&#x561B;&#xFF0C;&#x6765;&#x6D4B;&#x8BD5;&#x4E00;&#x4E0B;</p>
<pre><code>import requests

r = requests.get(&apos;https://kyfw.12306.cn/otn/&apos;, verify=True)
print r.text
</code></pre><p>&#x7ED3;&#x679C;</p>
<pre><code>requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)
</code></pre><p>&#x679C;&#x771F;&#x5982;&#x6B64;</p>
<p>&#x6765;&#x8BD5;&#x4E0B; github &#x7684;</p>
<pre><code>import requests

r = requests.get(&apos;https://github.com&apos;, verify=True)
print r.text
</code></pre><p>&#x55EF;&#xFF0C;&#x6B63;&#x5E38;&#x8BF7;&#x6C42;&#xFF0C;&#x5185;&#x5BB9;&#x6211;&#x5C31;&#x4E0D;&#x8F93;&#x51FA;&#x4E86;&#x3002;</p>
<p>&#x5982;&#x679C;&#x6211;&#x4EEC;&#x60F3;&#x8DF3;&#x8FC7;&#x521A;&#x624D; 12306 &#x7684;&#x8BC1;&#x4E66;&#x9A8C;&#x8BC1;&#xFF0C;&#x628A; verify &#x8BBE;&#x7F6E;&#x4E3A; False &#x5373;&#x53EF;</p>
<pre><code>import requests

r = requests.get(&apos;https://kyfw.12306.cn/otn/&apos;, verify=False)
print r.text
</code></pre><p>&#x53D1;&#x73B0;&#x5C31;&#x53EF;&#x4EE5;&#x6B63;&#x5E38;&#x8BF7;&#x6C42;&#x4E86;&#x3002;&#x5728;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B; verify &#x662F; True&#xFF0C;&#x6240;&#x4EE5;&#x5982;&#x679C;&#x9700;&#x8981;&#x7684;&#x8BDD;&#xFF0C;&#x9700;&#x8981;&#x624B;&#x52A8;&#x8BBE;&#x7F6E;&#x4E0B;&#x8FD9;&#x4E2A;&#x53D8;&#x91CF;&#x3002;</p>
<h2 id="&#x4EE3;&#x7406;">&#x4EE3;&#x7406;</h2>
<p>&#x5982;&#x679C;&#x9700;&#x8981;&#x4F7F;&#x7528;&#x4EE3;&#x7406;&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4E3A;&#x4EFB;&#x610F;&#x8BF7;&#x6C42;&#x65B9;&#x6CD5;&#x63D0;&#x4F9B; proxies &#x53C2;&#x6570;&#x6765;&#x914D;&#x7F6E;&#x5355;&#x4E2A;&#x8BF7;&#x6C42;</p>
<pre><code>import requests

proxies = {
  &quot;https&quot;: &quot;http://41.118.132.69:4433&quot;
}
r = requests.post(&quot;http://httpbin.org/post&quot;, proxies=proxies)
print r.text
</code></pre><p>&#x4E5F;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x73AF;&#x5883;&#x53D8;&#x91CF; HTTP_PROXY &#x548C; HTTPS_PROXY &#x6765;&#x914D;&#x7F6E;&#x4EE3;&#x7406;</p>
<pre><code>export HTTP_PROXY=&quot;http://10.10.1.10:3128&quot;
export HTTPS_PROXY=&quot;http://10.10.1.10:1080&quot;
</code></pre><p>&#x901A;&#x8FC7;&#x4EE5;&#x4E0A;&#x65B9;&#x5F0F;&#xFF0C;&#x53EF;&#x4EE5;&#x65B9;&#x4FBF;&#x5730;&#x8BBE;&#x7F6E;&#x4EE3;&#x7406;&#x3002;</p>
<h2 id="api">API</h2>
<p>&#x4EE5;&#x4E0A;&#x8BB2;&#x89E3;&#x4E86; requests &#x4E2D;&#x6700;&#x5E38;&#x7528;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x5982;&#x679C;&#x9700;&#x8981;&#x7528;&#x5230;&#x66F4;&#x591A;&#xFF0C;&#x8BF7;&#x53C2;&#x8003;&#x5B98;&#x65B9;&#x6587;&#x6863; <a href="http://docs.python-requests.org/en/master/api/" target="_blank">API</a></p>
<h2 id="&#x7ED3;&#x8BED;">&#x7ED3;&#x8BED;</h2>
<p>&#x4EE5;&#x4E0A;&#x603B;&#x7ED3;&#x4E86;&#x4E00;&#x4E0B; requests &#x7684;&#x57FA;&#x672C;&#x7528;&#x6CD5;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x5BF9;&#x722C;&#x866B;&#x6709;&#x4E86;&#x4E00;&#x5B9A;&#x7684;&#x57FA;&#x7840;&#xFF0C;&#x90A3;&#x4E48;&#x80AF;&#x5B9A;&#x53EF;&#x4EE5;&#x5F88;&#x5FEB;&#x4E0A;&#x624B;&#xFF0C;&#x5728;&#x6B64;&#x5C31;&#x4E0D;&#x591A;&#x8D58;&#x8FF0;&#x4E86;&#x3002;</p>
<p>&#x7EC3;&#x4E60;&#x624D;&#x662F;&#x738B;&#x9053;&#xFF0C;&#x5927;&#x5BB6;&#x5C3D;&#x5FEB;&#x6295;&#x6CE8;&#x4E8E;&#x5B9E;&#x8DF5;&#x4E2D;&#x5427;&#x3002;</p>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../chapter3/index.html" class="navigation navigation-prev " aria-label="Previous page: 三、爬虫利器"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../chapter3/section2.html" class="navigation navigation-next " aria-label="Next page: 2. Python爬虫利器二之Beautiful Soup的用法"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
