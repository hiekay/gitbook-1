<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>2. Python爬虫实战二之爬取百度贴吧帖子 | Python爬虫学习系列教程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../chapter2/section3.html" />
    
    
    <link rel="prev" href="../chapter2/section1.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="2.2"
        data-chapter-title="2. Python爬虫实战二之爬取百度贴吧帖子"
        data-filepath="chapter2/section2.md"
        data-basepath=".."
        data-revision="Wed Jun 21 2017 19:16:14 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Python爬虫学习系列教程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="chapter1/index.html">
            
                
                    <a href="../chapter1/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        一、爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="chapter1/section1.html">
            
                
                    <a href="../chapter1/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        1. Python爬虫入门一之综述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="chapter1/section2.html">
            
                
                    <a href="../chapter1/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        2. Python爬虫入门二之爬虫基础了解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="chapter1/section3.html">
            
                
                    <a href="../chapter1/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        3. Python爬虫入门三之Urllib库的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="chapter1/section4.html">
            
                
                    <a href="../chapter1/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        4. Python爬虫入门四之Urllib库的高级用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="chapter1/section5.html">
            
                
                    <a href="../chapter1/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.5.</b>
                        
                        5. Python爬虫入门五之URLError异常处理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="chapter1/section6.html">
            
                
                    <a href="../chapter1/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.6.</b>
                        
                        6. Python爬虫入门六之Cookie的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="chapter1/section7.html">
            
                
                    <a href="../chapter1/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.7.</b>
                        
                        7. Python爬虫入门七之正则表达式
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="chapter2/index.html">
            
                
                    <a href="../chapter2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        二、爬虫实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="chapter2/section1.html">
            
                
                    <a href="../chapter2/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        1. Python爬虫实战一之爬取糗事百科段子
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="2.2" data-path="chapter2/section2.html">
            
                
                    <a href="../chapter2/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        2. Python爬虫实战二之爬取百度贴吧帖子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="chapter2/section3.html">
            
                
                    <a href="../chapter2/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        3. Python爬虫实战三之实现山东大学无线网络掉线自动重连
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="chapter2/section4.html">
            
                
                    <a href="../chapter2/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        4. Python爬虫实战四之抓取淘宝MM照片
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="chapter2/section5.html">
            
                
                    <a href="../chapter2/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        5. Python爬虫实战五之模拟登录淘宝并获取所有订单
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="chapter2/section6.html">
            
                
                    <a href="../chapter2/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        6. Python爬虫实战六之抓取爱问知识人问题并保存至数据库
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="chapter2/section7.html">
            
                
                    <a href="../chapter2/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.</b>
                        
                        7. Python爬虫实战七之计算大学本学期绩点
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="chapter2/section8.html">
            
                
                    <a href="../chapter2/section8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.8.</b>
                        
                        8. Python爬虫实战八之利用Selenium抓取淘宝匿名旺旺
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="chapter3/index.html">
            
                
                    <a href="../chapter3/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        三、爬虫利器
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="chapter3/section1.html">
            
                
                    <a href="../chapter3/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        1. Python爬虫利器一之Requests库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="chapter3/section2.html">
            
                
                    <a href="../chapter3/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        2. Python爬虫利器二之Beautiful Soup的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="chapter3/section3.html">
            
                
                    <a href="../chapter3/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        3. Python爬虫利器三之Xpath语法与lxml库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="chapter3/section4.html">
            
                
                    <a href="../chapter3/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        4. Python爬虫利器四之PhantomJS的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="chapter3/section5.html">
            
                
                    <a href="../chapter3/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        5. Python爬虫利器五之Selenium的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="chapter3/section6.html">
            
                
                    <a href="../chapter3/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.6.</b>
                        
                        6. Python爬虫利器六之PyQuery的用法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="chapter4/index.html">
            
                
                    <a href="../chapter4/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        四、爬虫进阶
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="chapter4/section1.html">
            
                
                    <a href="../chapter4/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        1. Python爬虫进阶一之爬虫框架概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter4/section2.html">
            
                
                    <a href="../chapter4/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        2. Python爬虫进阶二之PySpider框架安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="chapter4/section3.html">
            
                
                    <a href="../chapter4/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        3. Python爬虫进阶三之爬虫框架Scrapy安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="chapter4/section4.html">
            
                
                    <a href="../chapter4/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        4. Python爬虫进阶四之PySpider的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="chapter4/section5.html">
            
                
                    <a href="../chapter4/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        5. Python爬虫进阶五之多线程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="chapter4/section6.html">
            
                
                    <a href="../chapter4/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.6.</b>
                        
                        6. Python爬虫进阶六之多进程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="chapter4/section7.html">
            
                
                    <a href="../chapter4/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.7.</b>
                        
                        7. Python爬虫进阶七之设置ADSL拨号服务器代理
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Python爬虫学习系列教程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="python&#x722C;&#x866B;&#x5B9E;&#x6218;&#x4E8C;&#x4E4B;&#x722C;&#x53D6;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x5E16;&#x5B50;">Python&#x722C;&#x866B;&#x5B9E;&#x6218;&#x4E8C;&#x4E4B;&#x722C;&#x53D6;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x5E16;&#x5B50;</h1>
<p>&#x5927;&#x5BB6;&#x597D;&#xFF0C;&#x4E0A;&#x6B21;&#x6211;&#x4EEC;&#x5B9E;&#x9A8C;&#x4E86;&#x722C;&#x53D6;&#x4E86;&#x7CD7;&#x4E8B;&#x767E;&#x79D1;&#x7684;&#x6BB5;&#x5B50;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x6B21;&#x6211;&#x4EEC;&#x6765;&#x5C1D;&#x8BD5;&#x4E00;&#x4E0B;&#x722C;&#x53D6;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x7684;&#x5E16;&#x5B50;&#x3002;&#x4E0E;&#x4E0A;&#x4E00;&#x7BC7;&#x4E0D;&#x540C;&#x7684;&#x662F;&#xFF0C;&#x8FD9;&#x6B21;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x7528;&#x5230;&#x6587;&#x4EF6;&#x7684;&#x76F8;&#x5173;&#x64CD;&#x4F5C;&#x3002;</p>
<h2 id="&#x524D;&#x8A00;">&#x524D;&#x8A00;</h2>
<p>&#x4EB2;&#x7231;&#x7684;&#x4EEC;&#xFF0C;&#x6559;&#x7A0B;&#x6BD4;&#x8F83;&#x65E7;&#x4E86;&#xFF0C;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x9875;&#x9762;&#x53EF;&#x80FD;&#x6539;&#x7248;&#xFF0C;&#x53EF;&#x80FD;&#x4EE3;&#x7801;&#x4E0D;&#x597D;&#x4F7F;&#xFF0C;&#x516B;&#x6210;&#x662F;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x90A3;&#x513F;&#x5339;&#x914D;&#x4E0D;&#x5230;&#x4E86;&#xFF0C;&#x8BF7;&#x66F4;&#x6539;&#x4E00;&#x4E0B;&#x6B63;&#x5219;&#xFF0C;&#x5F53;&#x7136;&#x6700;&#x4E3B;&#x8981;&#x7684;&#x8FD8;&#x662F;&#x5E2E;&#x52A9;&#x5927;&#x5BB6;&#x7406;&#x89E3;&#x601D;&#x8DEF;&#x3002;</p>
<p>2016/12/2</p>
<h2 id="&#x672C;&#x7BC7;&#x76EE;&#x6807;">&#x672C;&#x7BC7;&#x76EE;&#x6807;</h2>
<p>1.&#x5BF9;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x7684;&#x4EFB;&#x610F;&#x5E16;&#x5B50;&#x8FDB;&#x884C;&#x6293;&#x53D6;</p>
<p>2.&#x6307;&#x5B9A;&#x662F;&#x5426;&#x53EA;&#x6293;&#x53D6;&#x697C;&#x4E3B;&#x53D1;&#x5E16;&#x5185;&#x5BB9;</p>
<p>3.&#x5C06;&#x6293;&#x53D6;&#x5230;&#x7684;&#x5185;&#x5BB9;&#x5206;&#x6790;&#x5E76;&#x4FDD;&#x5B58;&#x5230;&#x6587;&#x4EF6;</p>
<h2 id="1url&#x683C;&#x5F0F;&#x7684;&#x786E;&#x5B9A;">1.URL&#x683C;&#x5F0F;&#x7684;&#x786E;&#x5B9A;</h2>
<p>&#x9996;&#x5148;&#xFF0C;&#x6211;&#x4EEC;&#x5148;&#x89C2;&#x5BDF;&#x4E00;&#x4E0B;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x7684;&#x4EFB;&#x610F;&#x4E00;&#x4E2A;&#x5E16;&#x5B50;&#x3002;</p>
<p>&#x6BD4;&#x5982;&#xFF1A;<a href="http://tieba.baidu.com/p/3138733512?see_lz=1&amp;pn=1&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x5173;&#x4E8E;NBA50&#x5927;&#x7684;&#x76D8;&#x70B9;&#xFF0C;&#x5206;&#x6790;&#x4E00;&#x4E0B;&#x8FD9;&#x4E2A;&#x5730;&#x5740;&#x3002;" target="_blank">http://tieba.baidu.com/p/3138733512?see_lz=1&amp;pn=1&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x5173;&#x4E8E;NBA50&#x5927;&#x7684;&#x76D8;&#x70B9;&#xFF0C;&#x5206;&#x6790;&#x4E00;&#x4E0B;&#x8FD9;&#x4E2A;&#x5730;&#x5740;&#x3002;</a></p>
<pre><code> http://  &#x4EE3;&#x8868;&#x8D44;&#x6E90;&#x4F20;&#x8F93;&#x4F7F;&#x7528;http&#x534F;&#x8BAE;
 tieba.baidu.com &#x662F;&#x767E;&#x5EA6;&#x7684;&#x4E8C;&#x7EA7;&#x57DF;&#x540D;&#xFF0C;&#x6307;&#x5411;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x7684;&#x670D;&#x52A1;&#x5668;&#x3002;
 /p/3138733512 &#x662F;&#x670D;&#x52A1;&#x5668;&#x67D0;&#x4E2A;&#x8D44;&#x6E90;&#xFF0C;&#x5373;&#x8FD9;&#x4E2A;&#x5E16;&#x5B50;&#x7684;&#x5730;&#x5740;&#x5B9A;&#x4F4D;&#x7B26;
 see_lz&#x548C;pn&#x662F;&#x8BE5;URL&#x7684;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#xFF0C;&#x5206;&#x522B;&#x4EE3;&#x8868;&#x4E86;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#x548C;&#x5E16;&#x5B50;&#x9875;&#x7801;&#xFF0C;&#x7B49;&#x4E8E;1&#x8868;&#x793A;&#x8BE5;&#x6761;&#x4EF6;&#x4E3A;&#x771F;
</code></pre><p>&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x628A;URL&#x5206;&#x4E3A;&#x4E24;&#x90E8;&#x5206;&#xFF0C;&#x4E00;&#x90E8;&#x5206;&#x4E3A;&#x57FA;&#x7840;&#x90E8;&#x5206;&#xFF0C;&#x4E00;&#x90E8;&#x5206;&#x4E3A;&#x53C2;&#x6570;&#x90E8;&#x5206;&#x3002;</p>
<p>&#x4F8B;&#x5982;&#xFF0C;&#x4E0A;&#x9762;&#x7684;URL&#x6211;&#x4EEC;&#x5212;&#x5206;&#x57FA;&#x7840;&#x90E8;&#x5206;&#x662F; <a href="http://tieba.baidu.com/p/3138733512&#xFF0C;&#x53C2;&#x6570;&#x90E8;&#x5206;&#x662F;" target="_blank">http://tieba.baidu.com/p/3138733512&#xFF0C;&#x53C2;&#x6570;&#x90E8;&#x5206;&#x662F;</a> ?see_lz=1&amp;pn=1</p>
<h2 id="2&#x9875;&#x9762;&#x7684;&#x6293;&#x53D6;">2.&#x9875;&#x9762;&#x7684;&#x6293;&#x53D6;</h2>
<p>&#x719F;&#x6089;&#x4E86;URL&#x7684;&#x683C;&#x5F0F;&#xFF0C;&#x90A3;&#x5C31;&#x8BA9;&#x6211;&#x4EEC;&#x7528;urllib2&#x5E93;&#x6765;&#x8BD5;&#x7740;&#x6293;&#x53D6;&#x9875;&#x9762;&#x5185;&#x5BB9;&#x5427;&#x3002;&#x4E0A;&#x4E00;&#x7BC7;&#x7CD7;&#x4E8B;&#x767E;&#x79D1;&#x6211;&#x4EEC;&#x6700;&#x540E;&#x6539;&#x6210;&#x4E86;&#x9762;&#x5411;&#x5BF9;&#x8C61;&#x7684;&#x7F16;&#x7801;&#x65B9;&#x5F0F;&#xFF0C;&#x8FD9;&#x6B21;&#x6211;&#x4EEC;&#x76F4;&#x63A5;&#x5C1D;&#x8BD5;&#x4E00;&#x4E0B;&#xFF0C;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x7C7B;&#x540D;&#x53EB;BDTB(&#x767E;&#x5EA6;&#x8D34;&#x5427;)&#xFF0C;&#x4E00;&#x4E2A;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;&#xFF0C;&#x4E00;&#x4E2A;&#x83B7;&#x53D6;&#x9875;&#x9762;&#x7684;&#x65B9;&#x6CD5;&#x3002;</p>
<p>&#x5176;&#x4E2D;&#xFF0C;&#x6709;&#x4E9B;&#x5E16;&#x5B50;&#x6211;&#x4EEC;&#x60F3;&#x6307;&#x5B9A;&#x7ED9;&#x7A0B;&#x5E8F;&#x662F;&#x5426;&#x8981;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x628A;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#x7684;&#x53C2;&#x6570;&#x521D;&#x59CB;&#x5316;&#x653E;&#x5728;&#x7C7B;&#x7684;&#x521D;&#x59CB;&#x5316;&#x4E0A;&#xFF0C;&#x5373;init&#x65B9;&#x6CD5;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x83B7;&#x53D6;&#x9875;&#x9762;&#x7684;&#x65B9;&#x6CD5;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x77E5;&#x9053;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x5C31;&#x662F;&#x5E16;&#x5B50;&#x9875;&#x7801;&#xFF0C;&#x6240;&#x4EE5;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x7684;&#x6307;&#x5B9A;&#x6211;&#x4EEC;&#x653E;&#x5728;&#x8BE5;&#x65B9;&#x6CD5;&#x4E2D;&#x3002;</p>
<p>&#x7EFC;&#x4E0A;&#xFF0C;&#x6211;&#x4EEC;&#x521D;&#x6B65;&#x6784;&#x5EFA;&#x51FA;&#x57FA;&#x7840;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre><code>__author__ = &apos;CQC&apos;
# -*- coding:utf-8 -*-
import urllib
import urllib2
import re

#&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x722C;&#x866B;&#x7C7B;
class BDTB:

    #&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x4F20;&#x5165;&#x57FA;&#x5730;&#x5740;&#xFF0C;&#x662F;&#x5426;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#x7684;&#x53C2;&#x6570;
    def __init__(self,baseUrl,seeLZ):
        self.baseURL = baseUrl
        self.seeLZ = &apos;?see_lz=&apos;+str(seeLZ)

    #&#x4F20;&#x5165;&#x9875;&#x7801;&#xFF0C;&#x83B7;&#x53D6;&#x8BE5;&#x9875;&#x5E16;&#x5B50;&#x7684;&#x4EE3;&#x7801;
    def getPage(self,pageNum):
        try:
            url = self.baseURL+ self.seeLZ + &apos;&amp;pn=&apos; + str(pageNum)
            request = urllib2.Request(url)
            response = urllib2.urlopen(request)
            print response.read()
            return response
        except urllib2.URLError, e:
            if hasattr(e,&quot;reason&quot;):
                print u&quot;&#x8FDE;&#x63A5;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x5931;&#x8D25;,&#x9519;&#x8BEF;&#x539F;&#x56E0;&quot;,e.reason
                return None

baseURL = &apos;http://tieba.baidu.com/p/3138733512&apos;
bdtb = BDTB(baseURL,1)
bdtb.getPage(1)
</code></pre><p>&#x8FD0;&#x884C;&#x4EE3;&#x7801;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x5C4F;&#x5E55;&#x4E0A;&#x6253;&#x5370;&#x51FA;&#x4E86;&#x8FD9;&#x4E2A;&#x5E16;&#x5B50;&#x7B2C;&#x4E00;&#x9875;&#x697C;&#x4E3B;&#x53D1;&#x8A00;&#x7684;&#x6240;&#x6709;&#x5185;&#x5BB9;&#xFF0C;&#x5F62;&#x5F0F;&#x4E3A;HTML&#x4EE3;&#x7801;&#x3002;</p>
<p><img src="../image/chapter2/section2-1.jpg" alt=""></p>
<h2 id="3&#x63D0;&#x53D6;&#x76F8;&#x5173;&#x4FE1;&#x606F;">3.&#x63D0;&#x53D6;&#x76F8;&#x5173;&#x4FE1;&#x606F;</h2>
<h3 id="1&#xFF09;&#x63D0;&#x53D6;&#x5E16;&#x5B50;&#x6807;&#x9898;">1&#xFF09;&#x63D0;&#x53D6;&#x5E16;&#x5B50;&#x6807;&#x9898;</h3>
<p>&#x9996;&#x5148;&#xFF0C;&#x8BA9;&#x6211;&#x4EEC;&#x63D0;&#x53D6;&#x5E16;&#x5B50;&#x7684;&#x6807;&#x9898;&#x3002;</p>
<p>&#x5728;&#x6D4F;&#x89C8;&#x5668;&#x4E2D;&#x5BA1;&#x67E5;&#x5143;&#x7D20;&#xFF0C;&#x6216;&#x8005;&#x6309;F12&#xFF0C;&#x67E5;&#x770B;&#x9875;&#x9762;&#x6E90;&#x4EE3;&#x7801;&#xFF0C;&#x6211;&#x4EEC;&#x627E;&#x5230;&#x6807;&#x9898;&#x6240;&#x5728;&#x7684;&#x4EE3;&#x7801;&#x6BB5;&#xFF0C;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#x8FD9;&#x4E2A;&#x6807;&#x9898;&#x7684;HTML&#x4EE3;&#x7801;&#x662F;</p>
<pre><code>&lt;h1 class=&quot;core_title_txt  &quot; title=&quot;&#x7EAF;&#x539F;&#x521B;&#x6211;&#x5FC3;&#x4E2D;&#x7684;NBA2014-2015&#x8D5B;&#x5B63;&#x73B0;&#x5F79;50&#x5927;&quot; style=&quot;width: 396px&quot;&gt;&#x7EAF;&#x539F;&#x521B;&#x6211;&#x5FC3;&#x4E2D;&#x7684;NBA2014-2015&#x8D5B;&#x5B63;&#x73B0;&#x5F79;50&#x5927;&lt;/h1&gt;
</code></pre><p>&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x60F3;&#x63D0;&#x53D6;<code>&lt;h1&gt;</code>&#x6807;&#x7B7E;&#x4E2D;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x540C;&#x65F6;&#x8FD8;&#x8981;&#x6307;&#x5B9A;&#x8FD9;&#x4E2A;class&#x786E;&#x5B9A;&#x552F;&#x4E00;&#xFF0C;&#x56E0;&#x4E3A;h1&#x6807;&#x7B7E;&#x5B9E;&#x5728;&#x592A;&#x591A;&#x5566;&#x3002;</p>
<p>&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x5982;&#x4E0B;</p>
<pre><code>&lt;h1 class=&quot;core_title_txt.*?&gt;(.*?)&lt;/h1&gt;
</code></pre><p>&#x6240;&#x4EE5;&#xFF0C;&#x6211;&#x4EEC;&#x589E;&#x52A0;&#x4E00;&#x4E2A;&#x83B7;&#x53D6;&#x9875;&#x9762;&#x6807;&#x9898;&#x7684;&#x65B9;&#x6CD5;</p>
<pre><code>#&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x6807;&#x9898;
def getTitle(self):
    page = self.getPage(1)
    pattern = re.compile(&apos;&lt;h1 class=&quot;core_title_txt.*?&gt;(.*?)&lt;/h1&gt;&apos;,re.S)
    result = re.search(pattern,page)
    if result:
        #print result.group(1)  #&#x6D4B;&#x8BD5;&#x8F93;&#x51FA;
        return result.group(1).strip()
    else:
        return None
</code></pre><h3 id="2&#xFF09;&#x63D0;&#x53D6;&#x5E16;&#x5B50;&#x9875;&#x6570;">2&#xFF09;&#x63D0;&#x53D6;&#x5E16;&#x5B50;&#x9875;&#x6570;</h3>
<p>&#x540C;&#x6837;&#x5730;&#xFF0C;&#x5E16;&#x5B50;&#x603B;&#x9875;&#x6570;&#x6211;&#x4EEC;&#x4E5F;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5206;&#x6790;&#x9875;&#x9762;&#x4E2D;&#x7684;&#x5171;?&#x9875;&#x6765;&#x83B7;&#x53D6;&#x3002;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x7684;&#x83B7;&#x53D6;&#x603B;&#x9875;&#x6570;&#x7684;&#x65B9;&#x6CD5;&#x5982;&#x4E0B;</p>
<pre><code>#&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x4E00;&#x5171;&#x6709;&#x591A;&#x5C11;&#x9875;
def getPageNum(self):
    page = self.getPage(1)
    pattern = re.compile(&apos;&lt;li class=&quot;l_reply_num.*?&lt;/span&gt;.*?&lt;span.*?&gt;(.*?)&lt;/span&gt;&apos;,re.S)
    result = re.search(pattern,page)
    if result:
        #print result.group(1)  #&#x6D4B;&#x8BD5;&#x8F93;&#x51FA;
        return result.group(1).strip()
    else:
        return None
</code></pre><h3 id="3&#xFF09;&#x63D0;&#x53D6;&#x6B63;&#x6587;&#x5185;&#x5BB9;">3&#xFF09;&#x63D0;&#x53D6;&#x6B63;&#x6587;&#x5185;&#x5BB9;</h3>
<p>&#x5BA1;&#x67E5;&#x5143;&#x7D20;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x6BCF;&#x4E00;&#x5C42;&#x697C;&#x7684;&#x4E3B;&#x8981;&#x5185;&#x5BB9;&#x90FD;&#x5728;<div id="&#x201D;post_content_xxxx&#x201D;"></div>&#x6807;&#x7B7E;&#x91CC;&#x9762;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5199;&#x5982;&#x4E0B;&#x7684;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;</p>
<pre><code>&lt;div id=&quot;post_content_.*?&gt;(.*?)&lt;/div&gt;
</code></pre><p>&#x76F8;&#x5E94;&#x5730;&#xFF0C;&#x83B7;&#x53D6;&#x9875;&#x9762;&#x6240;&#x6709;&#x697C;&#x5C42;&#x6570;&#x636E;&#x7684;&#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x5199;&#x6210;&#x5982;&#x4E0B;&#x65B9;&#x6CD5;</p>
<pre><code>#&#x83B7;&#x53D6;&#x6BCF;&#x4E00;&#x5C42;&#x697C;&#x7684;&#x5185;&#x5BB9;,&#x4F20;&#x5165;&#x9875;&#x9762;&#x5185;&#x5BB9;
def getContent(self,page):
    pattern = re.compile(&apos;&lt;div id=&quot;post_content_.*?&gt;(.*?)&lt;/div&gt;&apos;,re.S)
    items = re.findall(pattern,page)
    for item in items:
        print item
</code></pre><p>&#x597D;&#xFF0C;&#x6211;&#x4EEC;&#x8FD0;&#x884C;&#x4E00;&#x4E0B;&#x7ED3;&#x679C;&#x770B;&#x4E00;&#x4E0B;</p>
<p><img src="../image/chapter2/section2-2.jpg" alt=""></p>
<p>&#x771F;&#x662F;&#x9189;&#x4E86;&#xFF0C;&#x8FD8;&#x6709;&#x4E00;&#x5927;&#x7247;&#x6362;&#x884C;&#x7B26;&#x548C;&#x56FE;&#x7247;&#x7B26;&#xFF0C;&#x597D;&#x53E3;&#x6015;&#xFF01;&#x65E2;&#x7136;&#x8FD9;&#x6837;&#xFF0C;&#x6211;&#x4EEC;&#x5C31;&#x8981;&#x5BF9;&#x8FD9;&#x4E9B;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x5904;&#x7406;&#xFF0C;&#x628A;&#x5404;&#x79CD;&#x5404;&#x6837;&#x590D;&#x6742;&#x7684;&#x6807;&#x7B7E;&#x7ED9;&#x5B83;&#x5254;&#x9664;&#x6389;&#xFF0C;&#x8FD8;&#x539F;&#x7CBE;&#x534E;&#x5185;&#x5BB9;&#xFF0C;&#x628A;&#x6587;&#x672C;&#x5904;&#x7406;&#x5199;&#x6210;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#x4E5F;&#x53EF;&#x4EE5;&#xFF0C;&#x4E0D;&#x8FC7;&#x4E3A;&#x4E86;&#x5B9E;&#x73B0;&#x66F4;&#x597D;&#x7684;&#x4EE3;&#x7801;&#x67B6;&#x6784;&#x548C;&#x4EE3;&#x7801;&#x91CD;&#x7528;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x628A;&#x6807;&#x7B7E;&#x7B49;&#x7684;&#x5904;&#x7406;&#x5199;&#x4F5C;&#x4E00;&#x4E2A;&#x7C7B;&#x3002;</p>
<p>&#x90A3;&#x6211;&#x4EEC;&#x5C31;&#x53EB;&#x5B83;Tool&#xFF08;&#x5DE5;&#x5177;&#x7C7B;&#x5427;&#xFF09;&#xFF0C;&#x91CC;&#x9762;&#x5B9A;&#x4E49;&#x4E86;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#xFF0C;&#x53EB;replace&#xFF0C;&#x662F;&#x66FF;&#x6362;&#x5404;&#x79CD;&#x6807;&#x7B7E;&#x7684;&#x3002;&#x5728;&#x7C7B;&#x4E2D;&#x5B9A;&#x4E49;&#x4E86;&#x51E0;&#x4E2A;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x4E3B;&#x8981;&#x5229;&#x7528;&#x4E86;re.sub&#x65B9;&#x6CD5;&#x5BF9;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x5339;&#x914D;&#x540E;&#x7136;&#x540E;&#x66FF;&#x6362;&#x3002;&#x5177;&#x4F53;&#x7684;&#x601D;&#x8DEF;&#x5DF2;&#x7ECF;&#x5199;&#x5230;&#x6CE8;&#x91CA;&#x4E2D;&#xFF0C;&#x5927;&#x5BB6;&#x53EF;&#x4EE5;&#x770B;&#x4E00;&#x4E0B;&#x8FD9;&#x4E2A;&#x7C7B;</p>
<pre><code>import re

#&#x5904;&#x7406;&#x9875;&#x9762;&#x6807;&#x7B7E;&#x7C7B;
class Tool:
    #&#x53BB;&#x9664;img&#x6807;&#x7B7E;,7&#x4F4D;&#x957F;&#x7A7A;&#x683C;
    removeImg = re.compile(&apos;&lt;img.*?&gt;| {7}|&apos;)
    #&#x5220;&#x9664;&#x8D85;&#x94FE;&#x63A5;&#x6807;&#x7B7E;
    removeAddr = re.compile(&apos;&lt;a.*?&gt;|&lt;/a&gt;&apos;)
    #&#x628A;&#x6362;&#x884C;&#x7684;&#x6807;&#x7B7E;&#x6362;&#x4E3A;\n
    replaceLine = re.compile(&apos;&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;|&lt;/p&gt;&apos;)
    #&#x5C06;&#x8868;&#x683C;&#x5236;&#x8868;&lt;td&gt;&#x66FF;&#x6362;&#x4E3A;\t
    replaceTD= re.compile(&apos;&lt;td&gt;&apos;)
    #&#x628A;&#x6BB5;&#x843D;&#x5F00;&#x5934;&#x6362;&#x4E3A;\n&#x52A0;&#x7A7A;&#x4E24;&#x683C;
    replacePara = re.compile(&apos;&lt;p.*?&gt;&apos;)
    #&#x5C06;&#x6362;&#x884C;&#x7B26;&#x6216;&#x53CC;&#x6362;&#x884C;&#x7B26;&#x66FF;&#x6362;&#x4E3A;\n
    replaceBR = re.compile(&apos;&lt;br&gt;&lt;br&gt;|&lt;br&gt;&apos;)
    #&#x5C06;&#x5176;&#x4F59;&#x6807;&#x7B7E;&#x5254;&#x9664;
    removeExtraTag = re.compile(&apos;&lt;.*?&gt;&apos;)
    def replace(self,x):
        x = re.sub(self.removeImg,&quot;&quot;,x)
        x = re.sub(self.removeAddr,&quot;&quot;,x)
        x = re.sub(self.replaceLine,&quot;\n&quot;,x)
        x = re.sub(self.replaceTD,&quot;\t&quot;,x)
        x = re.sub(self.replacePara,&quot;\n    &quot;,x)
        x = re.sub(self.replaceBR,&quot;\n&quot;,x)
        x = re.sub(self.removeExtraTag,&quot;&quot;,x)
        #strip()&#x5C06;&#x524D;&#x540E;&#x591A;&#x4F59;&#x5185;&#x5BB9;&#x5220;&#x9664;
        return x.strip()
</code></pre><p>&#x5728;&#x4F7F;&#x7528;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x53EA;&#x9700;&#x8981;&#x521D;&#x59CB;&#x5316;&#x4E00;&#x4E0B;&#x8FD9;&#x4E2A;&#x7C7B;&#xFF0C;&#x7136;&#x540E;&#x8C03;&#x7528;replace&#x65B9;&#x6CD5;&#x5373;&#x53EF;&#x3002;</p>
<p>&#x73B0;&#x5728;&#x6574;&#x4F53;&#x4EE3;&#x7801;&#x662F;&#x5982;&#x4E0B;&#x8FD9;&#x6837;&#x5B50;&#x7684;&#xFF0C;&#x73B0;&#x5728;&#x6211;&#x7684;&#x4EE3;&#x7801;&#x662F;&#x5199;&#x5230;&#x8FD9;&#x6837;&#x5B50;&#x7684;</p>
<pre><code>__author__ = &apos;CQC&apos;
# -*- coding:utf-8 -*-
import urllib
import urllib2
import re

#&#x5904;&#x7406;&#x9875;&#x9762;&#x6807;&#x7B7E;&#x7C7B;
class Tool:
    #&#x53BB;&#x9664;img&#x6807;&#x7B7E;,7&#x4F4D;&#x957F;&#x7A7A;&#x683C;
    removeImg = re.compile(&apos;&lt;img.*?&gt;| {7}|&apos;)
    #&#x5220;&#x9664;&#x8D85;&#x94FE;&#x63A5;&#x6807;&#x7B7E;
    removeAddr = re.compile(&apos;&lt;a.*?&gt;|&lt;/a&gt;&apos;)
    #&#x628A;&#x6362;&#x884C;&#x7684;&#x6807;&#x7B7E;&#x6362;&#x4E3A;\n
    replaceLine = re.compile(&apos;&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;|&lt;/p&gt;&apos;)
    #&#x5C06;&#x8868;&#x683C;&#x5236;&#x8868;&lt;td&gt;&#x66FF;&#x6362;&#x4E3A;\t
    replaceTD= re.compile(&apos;&lt;td&gt;&apos;)
    #&#x628A;&#x6BB5;&#x843D;&#x5F00;&#x5934;&#x6362;&#x4E3A;\n&#x52A0;&#x7A7A;&#x4E24;&#x683C;
    replacePara = re.compile(&apos;&lt;p.*?&gt;&apos;)
    #&#x5C06;&#x6362;&#x884C;&#x7B26;&#x6216;&#x53CC;&#x6362;&#x884C;&#x7B26;&#x66FF;&#x6362;&#x4E3A;\n
    replaceBR = re.compile(&apos;&lt;br&gt;&lt;br&gt;|&lt;br&gt;&apos;)
    #&#x5C06;&#x5176;&#x4F59;&#x6807;&#x7B7E;&#x5254;&#x9664;
    removeExtraTag = re.compile(&apos;&lt;.*?&gt;&apos;)
    def replace(self,x):
        x = re.sub(self.removeImg,&quot;&quot;,x)
        x = re.sub(self.removeAddr,&quot;&quot;,x)
        x = re.sub(self.replaceLine,&quot;\n&quot;,x)
        x = re.sub(self.replaceTD,&quot;\t&quot;,x)
        x = re.sub(self.replacePara,&quot;\n    &quot;,x)
        x = re.sub(self.replaceBR,&quot;\n&quot;,x)
        x = re.sub(self.removeExtraTag,&quot;&quot;,x)
        #strip()&#x5C06;&#x524D;&#x540E;&#x591A;&#x4F59;&#x5185;&#x5BB9;&#x5220;&#x9664;
        return x.strip()


#&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x722C;&#x866B;&#x7C7B;
class BDTB:

    #&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x4F20;&#x5165;&#x57FA;&#x5730;&#x5740;&#xFF0C;&#x662F;&#x5426;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#x7684;&#x53C2;&#x6570;
    def __init__(self,baseUrl,seeLZ):
        self.baseURL = baseUrl
        self.seeLZ = &apos;?see_lz=&apos;+str(seeLZ)
        self.tool = Tool()
    #&#x4F20;&#x5165;&#x9875;&#x7801;&#xFF0C;&#x83B7;&#x53D6;&#x8BE5;&#x9875;&#x5E16;&#x5B50;&#x7684;&#x4EE3;&#x7801;
    def getPage(self,pageNum):
        try:
            url = self.baseURL+ self.seeLZ + &apos;&amp;pn=&apos; + str(pageNum)
            request = urllib2.Request(url)
            response = urllib2.urlopen(request)
            return response.read().decode(&apos;utf-8&apos;)
        except urllib2.URLError, e:
            if hasattr(e,&quot;reason&quot;):
                print u&quot;&#x8FDE;&#x63A5;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x5931;&#x8D25;,&#x9519;&#x8BEF;&#x539F;&#x56E0;&quot;,e.reason
                return None

    #&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x6807;&#x9898;
    def getTitle(self):
        page = self.getPage(1)
        pattern = re.compile(&apos;&lt;h1 class=&quot;core_title_txt.*?&gt;(.*?)&lt;/h1&gt;&apos;,re.S)
        result = re.search(pattern,page)
        if result:
            #print result.group(1)  #&#x6D4B;&#x8BD5;&#x8F93;&#x51FA;
            return result.group(1).strip()
        else:
            return None

    #&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x4E00;&#x5171;&#x6709;&#x591A;&#x5C11;&#x9875;
    def getPageNum(self):
        page = self.getPage(1)
        pattern = re.compile(&apos;&lt;li class=&quot;l_reply_num.*?&lt;/span&gt;.*?&lt;span.*?&gt;(.*?)&lt;/span&gt;&apos;,re.S)
        result = re.search(pattern,page)
        if result:
            #print result.group(1)  #&#x6D4B;&#x8BD5;&#x8F93;&#x51FA;
            return result.group(1).strip()
        else:
            return None

    #&#x83B7;&#x53D6;&#x6BCF;&#x4E00;&#x5C42;&#x697C;&#x7684;&#x5185;&#x5BB9;,&#x4F20;&#x5165;&#x9875;&#x9762;&#x5185;&#x5BB9;
    def getContent(self,page):
        pattern = re.compile(&apos;&lt;div id=&quot;post_content_.*?&gt;(.*?)&lt;/div&gt;&apos;,re.S)
        items = re.findall(pattern,page)
        #for item in items:
        #  print item
        print self.tool.replace(items[1])


baseURL = &apos;http://tieba.baidu.com/p/3138733512&apos;
bdtb = BDTB(baseURL,1)
bdtb.getContent(bdtb.getPage(1))
</code></pre><p>&#x6211;&#x4EEC;&#x5C1D;&#x8BD5;&#x4E00;&#x4E0B;&#xFF0C;&#x91CD;&#x65B0;&#x518D;&#x770B;&#x4E00;&#x4E0B;&#x6548;&#x679C;&#xFF0C;&#x8FD9;&#x4E0B;&#x7ECF;&#x8FC7;&#x5904;&#x7406;&#x4E4B;&#x540E;&#x5E94;&#x8BE5;&#x5C31;&#x6CA1;&#x95EE;&#x9898;&#x4E86;&#xFF0C;&#x662F;&#x4E0D;&#x662F;&#x611F;&#x89C9;&#x597D;&#x9178;&#x723D;&#xFF01;</p>
<p><img src="../image/chapter2/section2-3.jpg" alt=""></p>
<h3 id="4&#xFF09;&#x66FF;&#x6362;&#x697C;&#x5C42;">4&#xFF09;&#x66FF;&#x6362;&#x697C;&#x5C42;</h3>
<p>&#x81F3;&#x4E8E;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x611F;&#x89C9;&#x76F4;&#x63A5;&#x63D0;&#x53D6;&#x697C;&#x5C42;&#x6CA1;&#x4EC0;&#x4E48;&#x5FC5;&#x8981;&#x5440;&#xFF0C;&#x56E0;&#x4E3A;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#x7684;&#x8BDD;&#xFF0C;&#x6709;&#x4E9B;&#x697C;&#x5C42;&#x7684;&#x7F16;&#x53F7;&#x662F;&#x95F4;&#x9694;&#x7684;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x5F97;&#x5230;&#x7684;&#x697C;&#x5C42;&#x5E8F;&#x53F7;&#x662F;&#x4E0D;&#x8FDE;&#x7EED;&#x7684;&#xFF0C;&#x8FD9;&#x6837;&#x6211;&#x4EEC;&#x4FDD;&#x5B58;&#x4E0B;&#x6765;&#x4E5F;&#x6CA1;&#x4EC0;&#x4E48;&#x7528;&#x3002;</p>
<p>&#x6240;&#x4EE5;&#x53EF;&#x4EE5;&#x5C1D;&#x8BD5;&#x4E0B;&#x9762;&#x7684;&#x65B9;&#x6CD5;&#xFF1A;</p>
<blockquote>
<ul>
<li>1.&#x6BCF;&#x6253;&#x5370;&#x8F93;&#x51FA;&#x4E00;&#x6BB5;&#x697C;&#x5C42;&#xFF0C;&#x5199;&#x5165;&#x4E00;&#x884C;&#x6A2A;&#x7EBF;&#x6765;&#x95F4;&#x9694;&#xFF0C;&#x6216;&#x8005;&#x6362;&#x884C;&#x7B26;&#x4E5F;&#x597D;&#x3002;</li>
<li>2.&#x8BD5;&#x7740;&#x91CD;&#x65B0;&#x7F16;&#x4E00;&#x4E2A;&#x697C;&#x5C42;&#xFF0C;&#x6309;&#x7167;&#x987A;&#x5E8F;&#xFF0C;&#x8BBE;&#x7F6E;&#x4E00;&#x4E2A;&#x53D8;&#x91CF;&#xFF0C;&#x6BCF;&#x6253;&#x5370;&#x51FA;&#x4E00;&#x4E2A;&#x7ED3;&#x679C;&#x53D8;&#x91CF;&#x52A0;&#x4E00;&#xFF0C;&#x6253;&#x5370;&#x51FA;&#x8FD9;&#x4E2A;&#x53D8;&#x91CF;&#x5F53;&#x505A;&#x697C;&#x5C42;&#x3002;</li>
</ul>
</blockquote>
<p>&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x5C1D;&#x8BD5;&#x4E00;&#x4E0B;&#x5427;&#xFF0C;&#x770B;&#x770B;&#x6548;&#x679C;&#x600E;&#x6837;</p>
<p>&#x628A;getContent&#x65B9;&#x6CD5;&#x4FEE;&#x6539;&#x5982;&#x4E0B;</p>
<pre><code>#&#x83B7;&#x53D6;&#x6BCF;&#x4E00;&#x5C42;&#x697C;&#x7684;&#x5185;&#x5BB9;,&#x4F20;&#x5165;&#x9875;&#x9762;&#x5185;&#x5BB9;
def getContent(self,page):
    pattern = re.compile(&apos;&lt;div id=&quot;post_content_.*?&gt;(.*?)&lt;/div&gt;&apos;,re.S)
    items = re.findall(pattern,page)
    floor = 1
    for item in items:
        print floor,u&quot;&#x697C;------------------------------------------------------------------------------------------------------------------------------------\n&quot;
        print self.tool.replace(item)
        floor += 1
</code></pre><p>&#x8FD0;&#x884C;&#x4E00;&#x4E0B;&#x770B;&#x770B;&#x6548;&#x679C;</p>
<p><img src="../image/chapter2/section2-4.jpg" alt=""></p>
<p>&#x563F;&#x563F;&#xFF0C;&#x6548;&#x679C;&#x8FD8;&#x4E0D;&#x9519;&#x5427;&#xFF0C;&#x611F;&#x89C9;&#x771F;&#x9178;&#x723D;&#xFF01;&#x63A5;&#x4E0B;&#x6765;&#x6211;&#x4EEC;&#x5B8C;&#x5584;&#x4E00;&#x4E0B;&#xFF0C;&#x7136;&#x540E;&#x5199;&#x5165;&#x6587;&#x4EF6;</p>
<h2 id="4&#x5199;&#x5165;&#x6587;&#x4EF6;">4.&#x5199;&#x5165;&#x6587;&#x4EF6;</h2>
<p>&#x6700;&#x540E;&#x4FBF;&#x662F;&#x5199;&#x5165;&#x6587;&#x4EF6;&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;&#x8FC7;&#x7A0B;&#x5F88;&#x7B80;&#x5355;&#xFF0C;&#x5C31;&#x51E0;&#x53E5;&#x8BDD;&#x7684;&#x4EE3;&#x7801;&#x800C;&#x5DF2;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x5229;&#x7528;&#x4E86;&#x4EE5;&#x4E0B;&#x4E24;&#x53E5;</p>
<pre><code>file = open(&#x201C;tb.txt&#x201D;,&#x201D;w&#x201D;)
file.writelines(obj)
</code></pre><p>&#x8FD9;&#x91CC;&#x4E0D;&#x518D;&#x8D58;&#x8FF0;&#xFF0C;&#x7A0D;&#x540E;&#x76F4;&#x63A5;&#x8D34;&#x4E0A;&#x5B8C;&#x5584;&#x4E4B;&#x540E;&#x7684;&#x4EE3;&#x7801;&#x3002;</p>
<h2 id="5&#x5B8C;&#x5584;&#x4EE3;&#x7801;">5.&#x5B8C;&#x5584;&#x4EE3;&#x7801;</h2>
<p>&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x5BF9;&#x4EE3;&#x7801;&#x8FDB;&#x884C;&#x4F18;&#x5316;&#xFF0C;&#x91CD;&#x6784;&#xFF0C;&#x5728;&#x4E00;&#x4E9B;&#x5730;&#x65B9;&#x6DFB;&#x52A0;&#x5FC5;&#x8981;&#x7684;&#x6253;&#x5370;&#x4FE1;&#x606F;&#xFF0C;&#x6574;&#x7406;&#x5982;&#x4E0B;</p>
<pre><code>__author__ = &apos;CQC&apos;
# -*- coding:utf-8 -*-
import urllib
import urllib2
import re

#&#x5904;&#x7406;&#x9875;&#x9762;&#x6807;&#x7B7E;&#x7C7B;
class Tool:
    #&#x53BB;&#x9664;img&#x6807;&#x7B7E;,7&#x4F4D;&#x957F;&#x7A7A;&#x683C;
    removeImg = re.compile(&apos;&lt;img.*?&gt;| {7}|&apos;)
    #&#x5220;&#x9664;&#x8D85;&#x94FE;&#x63A5;&#x6807;&#x7B7E;
    removeAddr = re.compile(&apos;&lt;a.*?&gt;|&lt;/a&gt;&apos;)
    #&#x628A;&#x6362;&#x884C;&#x7684;&#x6807;&#x7B7E;&#x6362;&#x4E3A;\n
    replaceLine = re.compile(&apos;&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;|&lt;/p&gt;&apos;)
    #&#x5C06;&#x8868;&#x683C;&#x5236;&#x8868;&lt;td&gt;&#x66FF;&#x6362;&#x4E3A;\t
    replaceTD= re.compile(&apos;&lt;td&gt;&apos;)
    #&#x628A;&#x6BB5;&#x843D;&#x5F00;&#x5934;&#x6362;&#x4E3A;\n&#x52A0;&#x7A7A;&#x4E24;&#x683C;
    replacePara = re.compile(&apos;&lt;p.*?&gt;&apos;)
    #&#x5C06;&#x6362;&#x884C;&#x7B26;&#x6216;&#x53CC;&#x6362;&#x884C;&#x7B26;&#x66FF;&#x6362;&#x4E3A;\n
    replaceBR = re.compile(&apos;&lt;br&gt;&lt;br&gt;|&lt;br&gt;&apos;)
    #&#x5C06;&#x5176;&#x4F59;&#x6807;&#x7B7E;&#x5254;&#x9664;
    removeExtraTag = re.compile(&apos;&lt;.*?&gt;&apos;)
    def replace(self,x):
        x = re.sub(self.removeImg,&quot;&quot;,x)
        x = re.sub(self.removeAddr,&quot;&quot;,x)
        x = re.sub(self.replaceLine,&quot;\n&quot;,x)
        x = re.sub(self.replaceTD,&quot;\t&quot;,x)
        x = re.sub(self.replacePara,&quot;\n    &quot;,x)
        x = re.sub(self.replaceBR,&quot;\n&quot;,x)
        x = re.sub(self.removeExtraTag,&quot;&quot;,x)
        #strip()&#x5C06;&#x524D;&#x540E;&#x591A;&#x4F59;&#x5185;&#x5BB9;&#x5220;&#x9664;
        return x.strip()


#&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x722C;&#x866B;&#x7C7B;
class BDTB:

    #&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x4F20;&#x5165;&#x57FA;&#x5730;&#x5740;&#xFF0C;&#x662F;&#x5426;&#x53EA;&#x770B;&#x697C;&#x4E3B;&#x7684;&#x53C2;&#x6570;
    def __init__(self,baseUrl,seeLZ,floorTag):
        #base&#x94FE;&#x63A5;&#x5730;&#x5740;
        self.baseURL = baseUrl
        #&#x662F;&#x5426;&#x53EA;&#x770B;&#x697C;&#x4E3B;
        self.seeLZ = &apos;?see_lz=&apos;+str(seeLZ)
        #HTML&#x6807;&#x7B7E;&#x5254;&#x9664;&#x5DE5;&#x5177;&#x7C7B;&#x5BF9;&#x8C61;
        self.tool = Tool()
        #&#x5168;&#x5C40;file&#x53D8;&#x91CF;&#xFF0C;&#x6587;&#x4EF6;&#x5199;&#x5165;&#x64CD;&#x4F5C;&#x5BF9;&#x8C61;
        self.file = None
        #&#x697C;&#x5C42;&#x6807;&#x53F7;&#xFF0C;&#x521D;&#x59CB;&#x4E3A;1
        self.floor = 1
        #&#x9ED8;&#x8BA4;&#x7684;&#x6807;&#x9898;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x6210;&#x529F;&#x83B7;&#x53D6;&#x5230;&#x6807;&#x9898;&#x7684;&#x8BDD;&#x5219;&#x4F1A;&#x7528;&#x8FD9;&#x4E2A;&#x6807;&#x9898;
        self.defaultTitle = u&quot;&#x767E;&#x5EA6;&#x8D34;&#x5427;&quot;
        #&#x662F;&#x5426;&#x5199;&#x5165;&#x697C;&#x5206;&#x9694;&#x7B26;&#x7684;&#x6807;&#x8BB0;
        self.floorTag = floorTag

    #&#x4F20;&#x5165;&#x9875;&#x7801;&#xFF0C;&#x83B7;&#x53D6;&#x8BE5;&#x9875;&#x5E16;&#x5B50;&#x7684;&#x4EE3;&#x7801;
    def getPage(self,pageNum):
        try:
            #&#x6784;&#x5EFA;URL
            url = self.baseURL+ self.seeLZ + &apos;&amp;pn=&apos; + str(pageNum)
            request = urllib2.Request(url)
            response = urllib2.urlopen(request)
            #&#x8FD4;&#x56DE;UTF-8&#x683C;&#x5F0F;&#x7F16;&#x7801;&#x5185;&#x5BB9;
            return response.read().decode(&apos;utf-8&apos;)
        #&#x65E0;&#x6CD5;&#x8FDE;&#x63A5;&#xFF0C;&#x62A5;&#x9519;
        except urllib2.URLError, e:
            if hasattr(e,&quot;reason&quot;):
                print u&quot;&#x8FDE;&#x63A5;&#x767E;&#x5EA6;&#x8D34;&#x5427;&#x5931;&#x8D25;,&#x9519;&#x8BEF;&#x539F;&#x56E0;&quot;,e.reason
                return None

    #&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x6807;&#x9898;
    def getTitle(self,page):
        #&#x5F97;&#x5230;&#x6807;&#x9898;&#x7684;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;
        pattern = re.compile(&apos;&lt;h1 class=&quot;core_title_txt.*?&gt;(.*?)&lt;/h1&gt;&apos;,re.S)
        result = re.search(pattern,page)
        if result:
            #&#x5982;&#x679C;&#x5B58;&#x5728;&#xFF0C;&#x5219;&#x8FD4;&#x56DE;&#x6807;&#x9898;
            return result.group(1).strip()
        else:
            return None

    #&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x4E00;&#x5171;&#x6709;&#x591A;&#x5C11;&#x9875;
    def getPageNum(self,page):
        #&#x83B7;&#x53D6;&#x5E16;&#x5B50;&#x9875;&#x6570;&#x7684;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;
        pattern = re.compile(&apos;&lt;li class=&quot;l_reply_num.*?&lt;/span&gt;.*?&lt;span.*?&gt;(.*?)&lt;/span&gt;&apos;,re.S)
        result = re.search(pattern,page)
        if result:
            return result.group(1).strip()
        else:
            return None

    #&#x83B7;&#x53D6;&#x6BCF;&#x4E00;&#x5C42;&#x697C;&#x7684;&#x5185;&#x5BB9;,&#x4F20;&#x5165;&#x9875;&#x9762;&#x5185;&#x5BB9;
    def getContent(self,page):
        #&#x5339;&#x914D;&#x6240;&#x6709;&#x697C;&#x5C42;&#x7684;&#x5185;&#x5BB9;
        pattern = re.compile(&apos;&lt;div id=&quot;post_content_.*?&gt;(.*?)&lt;/div&gt;&apos;,re.S)
        items = re.findall(pattern,page)
        contents = []
        for item in items:
            #&#x5C06;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x53BB;&#x9664;&#x6807;&#x7B7E;&#x5904;&#x7406;&#xFF0C;&#x540C;&#x65F6;&#x5728;&#x524D;&#x540E;&#x52A0;&#x5165;&#x6362;&#x884C;&#x7B26;
            content = &quot;\n&quot;+self.tool.replace(item)+&quot;\n&quot;
            contents.append(content.encode(&apos;utf-8&apos;))
        return contents

    def setFileTitle(self,title):
        #&#x5982;&#x679C;&#x6807;&#x9898;&#x4E0D;&#x662F;&#x4E3A;None&#xFF0C;&#x5373;&#x6210;&#x529F;&#x83B7;&#x53D6;&#x5230;&#x6807;&#x9898;
        if title is not None:
            self.file = open(title + &quot;.txt&quot;,&quot;w+&quot;)
        else:
            self.file = open(self.defaultTitle + &quot;.txt&quot;,&quot;w+&quot;)

    def writeData(self,contents):
        #&#x5411;&#x6587;&#x4EF6;&#x5199;&#x5165;&#x6BCF;&#x4E00;&#x697C;&#x7684;&#x4FE1;&#x606F;
        for item in contents:
            if self.floorTag == &apos;1&apos;:
                #&#x697C;&#x4E4B;&#x95F4;&#x7684;&#x5206;&#x9694;&#x7B26;
                floorLine = &quot;\n&quot; + str(self.floor) + u&quot;-----------------------------------------------------------------------------------------\n&quot;
                self.file.write(floorLine)
            self.file.write(item)
            self.floor += 1

    def start(self):
        indexPage = self.getPage(1)
        pageNum = self.getPageNum(indexPage)
        title = self.getTitle(indexPage)
        self.setFileTitle(title)
        if pageNum == None:
            print &quot;URL&#x5DF2;&#x5931;&#x6548;&#xFF0C;&#x8BF7;&#x91CD;&#x8BD5;&quot;
            return
        try:
            print &quot;&#x8BE5;&#x5E16;&#x5B50;&#x5171;&#x6709;&quot; + str(pageNum) + &quot;&#x9875;&quot;
            for i in range(1,int(pageNum)+1):
                print &quot;&#x6B63;&#x5728;&#x5199;&#x5165;&#x7B2C;&quot; + str(i) + &quot;&#x9875;&#x6570;&#x636E;&quot;
                page = self.getPage(i)
                contents = self.getContent(page)
                self.writeData(contents)
        #&#x51FA;&#x73B0;&#x5199;&#x5165;&#x5F02;&#x5E38;
        except IOError,e:
            print &quot;&#x5199;&#x5165;&#x5F02;&#x5E38;&#xFF0C;&#x539F;&#x56E0;&quot; + e.message
        finally:
            print &quot;&#x5199;&#x5165;&#x4EFB;&#x52A1;&#x5B8C;&#x6210;&quot;



print u&quot;&#x8BF7;&#x8F93;&#x5165;&#x5E16;&#x5B50;&#x4EE3;&#x53F7;&quot;
baseURL = &apos;http://tieba.baidu.com/p/&apos; + str(raw_input(u&apos;http://tieba.baidu.com/p/&apos;))
seeLZ = raw_input(&quot;&#x662F;&#x5426;&#x53EA;&#x83B7;&#x53D6;&#x697C;&#x4E3B;&#x53D1;&#x8A00;&#xFF0C;&#x662F;&#x8F93;&#x5165;1&#xFF0C;&#x5426;&#x8F93;&#x5165;0\n&quot;)
floorTag = raw_input(&quot;&#x662F;&#x5426;&#x5199;&#x5165;&#x697C;&#x5C42;&#x4FE1;&#x606F;&#xFF0C;&#x662F;&#x8F93;&#x5165;1&#xFF0C;&#x5426;&#x8F93;&#x5165;0\n&quot;)
bdtb = BDTB(baseURL,seeLZ,floorTag)
bdtb.start()
</code></pre><p>&#x73B0;&#x5728;&#x7A0B;&#x5E8F;&#x6F14;&#x793A;&#x5982;&#x4E0B;</p>
<p><img src="../image/chapter2/section2-5.jpg" alt=""></p>
<p>&#x5B8C;&#x6210;&#x4E4B;&#x540E;&#xFF0C;&#x53EF;&#x4EE5;&#x67E5;&#x770B;&#x4E00;&#x4E0B;&#x5F53;&#x524D;&#x76EE;&#x5F55;&#x4E0B;&#x591A;&#x4E86;&#x4E00;&#x4E2A;&#x4EE5;&#x8BE5;&#x5E16;&#x5B50;&#x547D;&#x540D;&#x7684;txt&#x6587;&#x4EF6;&#xFF0C;&#x5185;&#x5BB9;&#x4FBF;&#x662F;&#x5E16;&#x5B50;&#x7684;&#x6240;&#x6709;&#x6570;&#x636E;&#x3002;</p>
<p>&#x6293;&#x8D34;&#x5427;&#xFF0C;&#x5C31;&#x662F;&#x8FD9;&#x4E48;&#x7B80;&#x5355;&#x548C;&#x4EFB;&#x6027;&#xFF01;</p>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../chapter2/section1.html" class="navigation navigation-prev " aria-label="Previous page: 1. Python爬虫实战一之爬取糗事百科段子"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../chapter2/section3.html" class="navigation navigation-next " aria-label="Next page: 3. Python爬虫实战三之实现山东大学无线网络掉线自动重连"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
