<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>4. Python爬虫入门四之Urllib库的高级用法 | Python爬虫学习系列教程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../chapter1/section5.html" />
    
    
    <link rel="prev" href="../chapter1/section3.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="1.4"
        data-chapter-title="4. Python爬虫入门四之Urllib库的高级用法"
        data-filepath="chapter1/section4.md"
        data-basepath=".."
        data-revision="Wed Jun 21 2017 19:16:14 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Python爬虫学习系列教程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="chapter1/index.html">
            
                
                    <a href="../chapter1/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        一、爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="chapter1/section1.html">
            
                
                    <a href="../chapter1/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        1. Python爬虫入门一之综述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="chapter1/section2.html">
            
                
                    <a href="../chapter1/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        2. Python爬虫入门二之爬虫基础了解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="chapter1/section3.html">
            
                
                    <a href="../chapter1/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        3. Python爬虫入门三之Urllib库的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="1.4" data-path="chapter1/section4.html">
            
                
                    <a href="../chapter1/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        4. Python爬虫入门四之Urllib库的高级用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="chapter1/section5.html">
            
                
                    <a href="../chapter1/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.5.</b>
                        
                        5. Python爬虫入门五之URLError异常处理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="chapter1/section6.html">
            
                
                    <a href="../chapter1/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.6.</b>
                        
                        6. Python爬虫入门六之Cookie的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="chapter1/section7.html">
            
                
                    <a href="../chapter1/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.7.</b>
                        
                        7. Python爬虫入门七之正则表达式
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="chapter2/index.html">
            
                
                    <a href="../chapter2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        二、爬虫实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="chapter2/section1.html">
            
                
                    <a href="../chapter2/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        1. Python爬虫实战一之爬取糗事百科段子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="chapter2/section2.html">
            
                
                    <a href="../chapter2/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        2. Python爬虫实战二之爬取百度贴吧帖子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="chapter2/section3.html">
            
                
                    <a href="../chapter2/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        3. Python爬虫实战三之实现山东大学无线网络掉线自动重连
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="chapter2/section4.html">
            
                
                    <a href="../chapter2/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        4. Python爬虫实战四之抓取淘宝MM照片
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="chapter2/section5.html">
            
                
                    <a href="../chapter2/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        5. Python爬虫实战五之模拟登录淘宝并获取所有订单
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="chapter2/section6.html">
            
                
                    <a href="../chapter2/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        6. Python爬虫实战六之抓取爱问知识人问题并保存至数据库
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="chapter2/section7.html">
            
                
                    <a href="../chapter2/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.</b>
                        
                        7. Python爬虫实战七之计算大学本学期绩点
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="chapter2/section8.html">
            
                
                    <a href="../chapter2/section8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.8.</b>
                        
                        8. Python爬虫实战八之利用Selenium抓取淘宝匿名旺旺
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="chapter3/index.html">
            
                
                    <a href="../chapter3/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        三、爬虫利器
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="chapter3/section1.html">
            
                
                    <a href="../chapter3/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        1. Python爬虫利器一之Requests库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="chapter3/section2.html">
            
                
                    <a href="../chapter3/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        2. Python爬虫利器二之Beautiful Soup的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="chapter3/section3.html">
            
                
                    <a href="../chapter3/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        3. Python爬虫利器三之Xpath语法与lxml库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="chapter3/section4.html">
            
                
                    <a href="../chapter3/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        4. Python爬虫利器四之PhantomJS的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="chapter3/section5.html">
            
                
                    <a href="../chapter3/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        5. Python爬虫利器五之Selenium的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="chapter3/section6.html">
            
                
                    <a href="../chapter3/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.6.</b>
                        
                        6. Python爬虫利器六之PyQuery的用法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="chapter4/index.html">
            
                
                    <a href="../chapter4/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        四、爬虫进阶
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="chapter4/section1.html">
            
                
                    <a href="../chapter4/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        1. Python爬虫进阶一之爬虫框架概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter4/section2.html">
            
                
                    <a href="../chapter4/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        2. Python爬虫进阶二之PySpider框架安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="chapter4/section3.html">
            
                
                    <a href="../chapter4/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        3. Python爬虫进阶三之爬虫框架Scrapy安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="chapter4/section4.html">
            
                
                    <a href="../chapter4/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        4. Python爬虫进阶四之PySpider的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="chapter4/section5.html">
            
                
                    <a href="../chapter4/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        5. Python爬虫进阶五之多线程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="chapter4/section6.html">
            
                
                    <a href="../chapter4/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.6.</b>
                        
                        6. Python爬虫进阶六之多进程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="chapter4/section7.html">
            
                
                    <a href="../chapter4/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.7.</b>
                        
                        7. Python爬虫进阶七之设置ADSL拨号服务器代理
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Python爬虫学习系列教程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="python&#x722C;&#x866B;&#x5165;&#x95E8;&#x56DB;&#x4E4B;urllib&#x5E93;&#x7684;&#x9AD8;&#x7EA7;&#x7528;&#x6CD5;">Python&#x722C;&#x866B;&#x5165;&#x95E8;&#x56DB;&#x4E4B;Urllib&#x5E93;&#x7684;&#x9AD8;&#x7EA7;&#x7528;&#x6CD5;</h1>
<h2 id="1&#x8BBE;&#x7F6E;headers">1.&#x8BBE;&#x7F6E;Headers</h2>
<p>&#x6709;&#x4E9B;&#x7F51;&#x7AD9;&#x4E0D;&#x4F1A;&#x540C;&#x610F;&#x7A0B;&#x5E8F;&#x76F4;&#x63A5;&#x7528;&#x4E0A;&#x9762;&#x7684;&#x65B9;&#x5F0F;&#x8FDB;&#x884C;&#x8BBF;&#x95EE;&#xFF0C;&#x5982;&#x679C;&#x8BC6;&#x522B;&#x6709;&#x95EE;&#x9898;&#xFF0C;&#x90A3;&#x4E48;&#x7AD9;&#x70B9;&#x6839;&#x672C;&#x4E0D;&#x4F1A;&#x54CD;&#x5E94;&#xFF0C;&#x6240;&#x4EE5;&#x4E3A;&#x4E86;&#x5B8C;&#x5168;&#x6A21;&#x62DF;&#x6D4F;&#x89C8;&#x5668;&#x7684;&#x5DE5;&#x4F5C;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x8BBE;&#x7F6E;&#x4E00;&#x4E9B;Headers &#x7684;&#x5C5E;&#x6027;&#x3002;</p>
<p>&#x9996;&#x5148;&#xFF0C;&#x6253;&#x5F00;&#x6211;&#x4EEC;&#x7684;&#x6D4F;&#x89C8;&#x5668;&#xFF0C;&#x8C03;&#x8BD5;&#x6D4F;&#x89C8;&#x5668;F12&#xFF0C;&#x6211;&#x7528;&#x7684;&#x662F;Chrome&#xFF0C;&#x6253;&#x5F00;&#x7F51;&#x7EDC;&#x76D1;&#x542C;&#xFF0C;&#x793A;&#x610F;&#x5982;&#x4E0B;&#xFF0C;&#x6BD4;&#x5982;&#x77E5;&#x4E4E;&#xFF0C;&#x70B9;&#x767B;&#x5F55;&#x4E4B;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x4F1A;&#x53D1;&#x73B0;&#x767B;&#x9646;&#x4E4B;&#x540E;&#x754C;&#x9762;&#x90FD;&#x53D8;&#x5316;&#x4E86;&#xFF0C;&#x51FA;&#x73B0;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x754C;&#x9762;&#xFF0C;&#x5B9E;&#x8D28;&#x4E0A;&#x8FD9;&#x4E2A;&#x9875;&#x9762;&#x5305;&#x542B;&#x4E86;&#x8BB8;&#x8BB8;&#x591A;&#x591A;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x8FD9;&#x4E9B;&#x5185;&#x5BB9;&#x4E5F;&#x4E0D;&#x662F;&#x4E00;&#x6B21;&#x6027;&#x5C31;&#x52A0;&#x8F7D;&#x5B8C;&#x6210;&#x7684;&#xFF0C;&#x5B9E;&#x8D28;&#x4E0A;&#x662F;&#x6267;&#x884C;&#x4E86;&#x597D;&#x591A;&#x6B21;&#x8BF7;&#x6C42;&#xFF0C;&#x4E00;&#x822C;&#x662F;&#x9996;&#x5148;&#x8BF7;&#x6C42;HTML&#x6587;&#x4EF6;&#xFF0C;&#x7136;&#x540E;&#x52A0;&#x8F7D;JS&#xFF0C;CSS &#x7B49;&#x7B49;&#xFF0C;&#x7ECF;&#x8FC7;&#x591A;&#x6B21;&#x8BF7;&#x6C42;&#x4E4B;&#x540E;&#xFF0C;&#x7F51;&#x9875;&#x7684;&#x9AA8;&#x67B6;&#x548C;&#x808C;&#x8089;&#x5168;&#x4E86;&#xFF0C;&#x6574;&#x4E2A;&#x7F51;&#x9875;&#x7684;&#x6548;&#x679C;&#x4E5F;&#x5C31;&#x51FA;&#x6765;&#x4E86;&#x3002;</p>
<p><img src="../image/chapter1/section4-1.png" alt=""></p>
<p>&#x62C6;&#x5206;&#x8FD9;&#x4E9B;&#x8BF7;&#x6C42;&#xFF0C;&#x6211;&#x4EEC;&#x53EA;&#x770B;&#x4E00;&#x7B2C;&#x4E00;&#x4E2A;&#x8BF7;&#x6C42;&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;&#x6709;&#x4E2A;Request URL&#xFF0C;&#x8FD8;&#x6709;headers&#xFF0C;&#x4E0B;&#x9762;&#x4FBF;&#x662F;response&#xFF0C;&#x56FE;&#x7247;&#x663E;&#x793A;&#x5F97;&#x4E0D;&#x5168;&#xFF0C;&#x5C0F;&#x4F19;&#x4F34;&#x4EEC;&#x53EF;&#x4EE5;&#x4EB2;&#x8EAB;&#x5B9E;&#x9A8C;&#x4E00;&#x4E0B;&#x3002;&#x90A3;&#x4E48;&#x8FD9;&#x4E2A;&#x5934;&#x4E2D;&#x5305;&#x542B;&#x4E86;&#x8BB8;&#x8BB8;&#x591A;&#x591A;&#x662F;&#x4FE1;&#x606F;&#xFF0C;&#x6709;&#x6587;&#x4EF6;&#x7F16;&#x7801;&#x5566;&#xFF0C;&#x538B;&#x7F29;&#x65B9;&#x5F0F;&#x5566;&#xFF0C;&#x8BF7;&#x6C42;&#x7684;agent&#x5566;&#x7B49;&#x7B49;&#x3002;</p>
<p>&#x5176;&#x4E2D;&#xFF0C;agent&#x5C31;&#x662F;&#x8BF7;&#x6C42;&#x7684;&#x8EAB;&#x4EFD;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x5199;&#x5165;&#x8BF7;&#x6C42;&#x8EAB;&#x4EFD;&#xFF0C;&#x90A3;&#x4E48;&#x670D;&#x52A1;&#x5668;&#x4E0D;&#x4E00;&#x5B9A;&#x4F1A;&#x54CD;&#x5E94;&#xFF0C;&#x6240;&#x4EE5;&#x53EF;&#x4EE5;&#x5728;headers&#x4E2D;&#x8BBE;&#x7F6E;agent,&#x4F8B;&#x5982;&#x4E0B;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#xFF0C;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x53EA;&#x662F;&#x8BF4;&#x660E;&#x4E86;&#x600E;&#x6837;&#x8BBE;&#x7F6E;&#x7684;headers&#xFF0C;&#x5C0F;&#x4F19;&#x4F34;&#x4EEC;&#x770B;&#x4E00;&#x4E0B;&#x8BBE;&#x7F6E;&#x683C;&#x5F0F;&#x5C31;&#x597D;&#x3002;</p>
<pre><code>import urllib  
import urllib2  

url = &apos;http://www.server.com/login&apos;
user_agent = &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos;  
values = {&apos;username&apos; : &apos;cqc&apos;,  &apos;password&apos; : &apos;XXXX&apos; }  
headers = { &apos;User-Agent&apos; : user_agent }  
data = urllib.urlencode(values)  
request = urllib2.Request(url, data, headers)  
response = urllib2.urlopen(request)  
page = response.read()
</code></pre><p>&#x8FD9;&#x6837;&#xFF0C;&#x6211;&#x4EEC;&#x8BBE;&#x7F6E;&#x4E86;&#x4E00;&#x4E2A;headers&#xFF0C;&#x5728;&#x6784;&#x5EFA;request&#x65F6;&#x4F20;&#x5165;&#xFF0C;&#x5728;&#x8BF7;&#x6C42;&#x65F6;&#xFF0C;&#x5C31;&#x52A0;&#x5165;&#x4E86;headers&#x4F20;&#x9001;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x82E5;&#x8BC6;&#x522B;&#x4E86;&#x662F;&#x6D4F;&#x89C8;&#x5668;&#x53D1;&#x6765;&#x7684;&#x8BF7;&#x6C42;&#xFF0C;&#x5C31;&#x4F1A;&#x5F97;&#x5230;&#x54CD;&#x5E94;&#x3002;</p>
<p>&#x53E6;&#x5916;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x6709;&#x5BF9;&#x4ED8;&#x201D;&#x53CD;&#x76D7;&#x94FE;&#x201D;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x5BF9;&#x4ED8;&#x9632;&#x76D7;&#x94FE;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x4F1A;&#x8BC6;&#x522B;headers&#x4E2D;&#x7684;referer&#x662F;&#x4E0D;&#x662F;&#x5B83;&#x81EA;&#x5DF1;&#xFF0C;&#x5982;&#x679C;&#x4E0D;&#x662F;&#xFF0C;&#x6709;&#x7684;&#x670D;&#x52A1;&#x5668;&#x4E0D;&#x4F1A;&#x54CD;&#x5E94;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x8FD8;&#x53EF;&#x4EE5;&#x5728;headers&#x4E2D;&#x52A0;&#x5165;referer</p>
<p>&#x4F8B;&#x5982;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6784;&#x5EFA;&#x4E0B;&#x9762;&#x7684;headers</p>
<pre><code>headers = { &apos;User-Agent&apos; : &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos;  ,
                        &apos;Referer&apos;:&apos;http://www.zhihu.com/articles&apos; }
</code></pre><p>&#x540C;&#x4E0A;&#x9762;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5728;&#x4F20;&#x9001;&#x8BF7;&#x6C42;&#x65F6;&#x628A;headers&#x4F20;&#x5165;Request&#x53C2;&#x6570;&#x91CC;&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x80FD;&#x5E94;&#x4ED8;&#x9632;&#x76D7;&#x94FE;&#x4E86;&#x3002;</p>
<p>&#x53E6;&#x5916;headers&#x7684;&#x4E00;&#x4E9B;&#x5C5E;&#x6027;&#xFF0C;&#x4E0B;&#x9762;&#x7684;&#x9700;&#x8981;&#x7279;&#x522B;&#x6CE8;&#x610F;&#x4E00;&#x4E0B;&#xFF1A;</p>
<blockquote>
<ul>
<li>User-Agent : &#x6709;&#x4E9B;&#x670D;&#x52A1;&#x5668;&#x6216; Proxy &#x4F1A;&#x901A;&#x8FC7;&#x8BE5;&#x503C;&#x6765;&#x5224;&#x65AD;&#x662F;&#x5426;&#x662F;&#x6D4F;&#x89C8;&#x5668;&#x53D1;&#x51FA;&#x7684;&#x8BF7;&#x6C42;</li>
<li>Content-Type : &#x5728;&#x4F7F;&#x7528; REST &#x63A5;&#x53E3;&#x65F6;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x4F1A;&#x68C0;&#x67E5;&#x8BE5;&#x503C;&#xFF0C;&#x7528;&#x6765;&#x786E;&#x5B9A; HTTP Body &#x4E2D;&#x7684;&#x5185;&#x5BB9;&#x8BE5;&#x600E;&#x6837;&#x89E3;&#x6790;&#x3002;</li>
<li>application/xml &#xFF1A; &#x5728; XML RPC&#xFF0C;&#x5982; RESTful/SOAP &#x8C03;&#x7528;&#x65F6;&#x4F7F;&#x7528;</li>
<li>application/json &#xFF1A; &#x5728; JSON RPC &#x8C03;&#x7528;&#x65F6;&#x4F7F;&#x7528;</li>
<li>application/x-www-form-urlencoded &#xFF1A; &#x6D4F;&#x89C8;&#x5668;&#x63D0;&#x4EA4; Web &#x8868;&#x5355;&#x65F6;&#x4F7F;&#x7528;</li>
</ul>
<p>&#x5728;&#x4F7F;&#x7528;&#x670D;&#x52A1;&#x5668;&#x63D0;&#x4F9B;&#x7684; RESTful &#x6216; SOAP &#x670D;&#x52A1;&#x65F6;&#xFF0C; Content-Type &#x8BBE;&#x7F6E;&#x9519;&#x8BEF;&#x4F1A;&#x5BFC;&#x81F4;&#x670D;&#x52A1;&#x5668;&#x62D2;&#x7EDD;&#x670D;&#x52A1;</p>
</blockquote>
<p>&#x5176;&#x4ED6;&#x7684;&#x6709;&#x5FC5;&#x8981;&#x7684;&#x53EF;&#x4EE5;&#x5BA1;&#x67E5;&#x6D4F;&#x89C8;&#x5668;&#x7684;headers&#x5185;&#x5BB9;&#xFF0C;&#x5728;&#x6784;&#x5EFA;&#x65F6;&#x5199;&#x5165;&#x540C;&#x6837;&#x7684;&#x6570;&#x636E;&#x5373;&#x53EF;&#x3002;</p>
<h2 id="2-proxy&#xFF08;&#x4EE3;&#x7406;&#xFF09;&#x7684;&#x8BBE;&#x7F6E;">2. Proxy&#xFF08;&#x4EE3;&#x7406;&#xFF09;&#x7684;&#x8BBE;&#x7F6E;</h2>
<p>urllib2 &#x9ED8;&#x8BA4;&#x4F1A;&#x4F7F;&#x7528;&#x73AF;&#x5883;&#x53D8;&#x91CF; http_proxy &#x6765;&#x8BBE;&#x7F6E; HTTP Proxy&#x3002;&#x5047;&#x5982;&#x4E00;&#x4E2A;&#x7F51;&#x7AD9;&#x5B83;&#x4F1A;&#x68C0;&#x6D4B;&#x67D0;&#x4E00;&#x6BB5;&#x65F6;&#x95F4;&#x67D0;&#x4E2A;IP &#x7684;&#x8BBF;&#x95EE;&#x6B21;&#x6570;&#xFF0C;&#x5982;&#x679C;&#x8BBF;&#x95EE;&#x6B21;&#x6570;&#x8FC7;&#x591A;&#xFF0C;&#x5B83;&#x4F1A;&#x7981;&#x6B62;&#x4F60;&#x7684;&#x8BBF;&#x95EE;&#x3002;&#x6240;&#x4EE5;&#x4F60;&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;&#x4E00;&#x4E9B;&#x4EE3;&#x7406;&#x670D;&#x52A1;&#x5668;&#x6765;&#x5E2E;&#x52A9;&#x4F60;&#x505A;&#x5DE5;&#x4F5C;&#xFF0C;&#x6BCF;&#x9694;&#x4E00;&#x6BB5;&#x65F6;&#x95F4;&#x6362;&#x4E00;&#x4E2A;&#x4EE3;&#x7406;&#xFF0C;&#x7F51;&#x7AD9;&#x541B;&#x90FD;&#x4E0D;&#x77E5;&#x9053;&#x662F;&#x8C01;&#x5728;&#x6363;&#x9B3C;&#x4E86;&#xFF0C;&#x8FD9;&#x9178;&#x723D;&#xFF01;</p>
<p>&#x4E0B;&#x9762;&#x4E00;&#x6BB5;&#x4EE3;&#x7801;&#x8BF4;&#x660E;&#x4E86;&#x4EE3;&#x7406;&#x7684;&#x8BBE;&#x7F6E;&#x7528;&#x6CD5;</p>
<pre><code>import urllib2
enable_proxy = True
proxy_handler = urllib2.ProxyHandler({&quot;http&quot; : &apos;http://some-proxy.com:8080&apos;})
null_proxy_handler = urllib2.ProxyHandler({})
if enable_proxy:
    opener = urllib2.build_opener(proxy_handler)
else:
    opener = urllib2.build_opener(null_proxy_handler)
urllib2.install_opener(opener)
</code></pre><h2 id="3timeout-&#x8BBE;&#x7F6E;">3.Timeout &#x8BBE;&#x7F6E;</h2>
<p>&#x4E0A;&#x4E00;&#x8282;&#x5DF2;&#x7ECF;&#x8BF4;&#x8FC7;urlopen&#x65B9;&#x6CD5;&#x4E86;&#xFF0C;&#x7B2C;&#x4E09;&#x4E2A;&#x53C2;&#x6570;&#x5C31;&#x662F;timeout&#x7684;&#x8BBE;&#x7F6E;&#xFF0C;&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;&#x7B49;&#x5F85;&#x591A;&#x4E45;&#x8D85;&#x65F6;&#xFF0C;&#x4E3A;&#x4E86;&#x89E3;&#x51B3;&#x4E00;&#x4E9B;&#x7F51;&#x7AD9;&#x5B9E;&#x5728;&#x54CD;&#x5E94;&#x8FC7;&#x6162;&#x800C;&#x9020;&#x6210;&#x7684;&#x5F71;&#x54CD;&#x3002;</p>
<p>&#x4F8B;&#x5982;&#x4E0B;&#x9762;&#x7684;&#x4EE3;&#x7801;,&#x5982;&#x679C;&#x7B2C;&#x4E8C;&#x4E2A;&#x53C2;&#x6570;data&#x4E3A;&#x7A7A;&#x90A3;&#x4E48;&#x8981;&#x7279;&#x522B;&#x6307;&#x5B9A;&#x662F;timeout&#x662F;&#x591A;&#x5C11;&#xFF0C;&#x5199;&#x660E;&#x5F62;&#x53C2;&#xFF0C;&#x5982;&#x679C;data&#x5DF2;&#x7ECF;&#x4F20;&#x5165;&#xFF0C;&#x5219;&#x4E0D;&#x5FC5;&#x58F0;&#x660E;&#x3002;</p>
<pre><code>import urllib2
response = urllib2.urlopen(&apos;http://www.baidu.com&apos;, timeout=10)
</code></pre><pre><code>import urllib2
response = urllib2.urlopen(&apos;http://www.baidu.com&apos;,data, 10)
</code></pre><h2 id="4&#x4F7F;&#x7528;-http-&#x7684;-put-&#x548C;-delete-&#x65B9;&#x6CD5;">4.&#x4F7F;&#x7528; HTTP &#x7684; PUT &#x548C; DELETE &#x65B9;&#x6CD5;</h2>
<p>http&#x534F;&#x8BAE;&#x6709;&#x516D;&#x79CD;&#x8BF7;&#x6C42;&#x65B9;&#x6CD5;&#xFF0C;get,head,put,delete,post,options&#xFF0C;&#x6211;&#x4EEC;&#x6709;&#x65F6;&#x5019;&#x9700;&#x8981;&#x7528;&#x5230;PUT&#x65B9;&#x5F0F;&#x6216;&#x8005;DELETE&#x65B9;&#x5F0F;&#x8BF7;&#x6C42;&#x3002;</p>
<blockquote>
<ul>
<li>PUT&#xFF1A;&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x6BD4;&#x8F83;&#x5C11;&#x89C1;&#x3002;HTML&#x8868;&#x5355;&#x4E5F;&#x4E0D;&#x652F;&#x6301;&#x8FD9;&#x4E2A;&#x3002;&#x672C;&#x8D28;&#x4E0A;&#x6765;&#x8BB2;&#xFF0C; PUT&#x548C;POST&#x6781;&#x4E3A;&#x76F8;&#x4F3C;&#xFF0C;&#x90FD;&#x662F;&#x5411;&#x670D;&#x52A1;&#x5668;&#x53D1;&#x9001;&#x6570;&#x636E;&#xFF0C;&#x4F46;&#x5B83;&#x4EEC;&#x4E4B;&#x95F4;&#x6709;&#x4E00;&#x4E2A;&#x91CD;&#x8981;&#x533A;&#x522B;&#xFF0C;PUT&#x901A;&#x5E38;&#x6307;&#x5B9A;&#x4E86;&#x8D44;&#x6E90;&#x7684;&#x5B58;&#x653E;&#x4F4D;&#x7F6E;&#xFF0C;&#x800C;POST&#x5219;&#x6CA1;&#x6709;&#xFF0C;POST&#x7684;&#x6570;&#x636E;&#x5B58;&#x653E;&#x4F4D;&#x7F6E;&#x7531;&#x670D;&#x52A1;&#x5668;&#x81EA;&#x5DF1;&#x51B3;&#x5B9A;&#x3002;</li>
<li>DELETE&#xFF1A;&#x5220;&#x9664;&#x67D0;&#x4E00;&#x4E2A;&#x8D44;&#x6E90;&#x3002;&#x57FA;&#x672C;&#x4E0A;&#x8FD9;&#x4E2A;&#x4E5F;&#x5F88;&#x5C11;&#x89C1;&#xFF0C;&#x4E0D;&#x8FC7;&#x8FD8;&#x662F;&#x6709;&#x4E00;&#x4E9B;&#x5730;&#x65B9;&#x6BD4;&#x5982;amazon&#x7684;S3&#x4E91;&#x670D;&#x52A1;&#x91CC;&#x9762;&#x5C31;&#x7528;&#x7684;&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x6765;&#x5220;&#x9664;&#x8D44;&#x6E90;&#x3002;</li>
</ul>
</blockquote>
<p>&#x5982;&#x679C;&#x8981;&#x4F7F;&#x7528; HTTP PUT &#x548C; DELETE &#xFF0C;&#x53EA;&#x80FD;&#x4F7F;&#x7528;&#x6BD4;&#x8F83;&#x4F4E;&#x5C42;&#x7684; httplib &#x5E93;&#x3002;&#x867D;&#x7136;&#x5982;&#x6B64;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x662F;&#x80FD;&#x901A;&#x8FC7;&#x4E0B;&#x9762;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x4F7F; urllib2 &#x80FD;&#x591F;&#x53D1;&#x51FA; PUT &#x6216;DELETE &#x7684;&#x8BF7;&#x6C42;&#xFF0C;&#x4E0D;&#x8FC7;&#x7528;&#x7684;&#x6B21;&#x6570;&#x7684;&#x786E;&#x662F;&#x5C11;&#xFF0C;&#x5728;&#x8FD9;&#x91CC;&#x63D0;&#x4E00;&#x4E0B;&#x3002;</p>
<pre><code>import urllib2
request = urllib2.Request(uri, data=data)
request.get_method = lambda: &apos;PUT&apos; # or &apos;DELETE&apos;
response = urllib2.urlopen(request)
</code></pre><h2 id="5&#x4F7F;&#x7528;debuglog">5.&#x4F7F;&#x7528;DebugLog</h2>
<p>&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4E0B;&#x9762;&#x7684;&#x65B9;&#x6CD5;&#x628A; Debug Log &#x6253;&#x5F00;&#xFF0C;&#x8FD9;&#x6837;&#x6536;&#x53D1;&#x5305;&#x7684;&#x5185;&#x5BB9;&#x5C31;&#x4F1A;&#x5728;&#x5C4F;&#x5E55;&#x4E0A;&#x6253;&#x5370;&#x51FA;&#x6765;&#xFF0C;&#x65B9;&#x4FBF;&#x8C03;&#x8BD5;&#xFF0C;&#x8FD9;&#x4E2A;&#x4E5F;&#x4E0D;&#x592A;&#x5E38;&#x7528;&#xFF0C;&#x4EC5;&#x63D0;&#x4E00;&#x4E0B;</p>
<pre><code>import urllib2
httpHandler = urllib2.HTTPHandler(debuglevel=1)
httpsHandler = urllib2.HTTPSHandler(debuglevel=1)
opener = urllib2.build_opener(httpHandler, httpsHandler)
urllib2.install_opener(opener)
response = urllib2.urlopen(&apos;http://www.baidu.com&apos;)
</code></pre><p>&#x4EE5;&#x4E0A;&#x4FBF;&#x662F;&#x4E00;&#x90E8;&#x5206;&#x9AD8;&#x7EA7;&#x7279;&#x6027;&#xFF0C;&#x524D;&#x4E09;&#x4E2A;&#x662F;&#x91CD;&#x8981;&#x5185;&#x5BB9;&#xFF0C;&#x5728;&#x540E;&#x9762;&#xFF0C;&#x8FD8;&#x6709;cookies&#x7684;&#x8BBE;&#x7F6E;&#x8FD8;&#x6709;&#x5F02;&#x5E38;&#x7684;&#x5904;&#x7406;&#xFF0C;&#x5C0F;&#x4F19;&#x4F34;&#x4EEC;&#x52A0;&#x6CB9;&#xFF01;</p>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../chapter1/section3.html" class="navigation navigation-prev " aria-label="Previous page: 3. Python爬虫入门三之Urllib库的基本使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../chapter1/section5.html" class="navigation navigation-next " aria-label="Next page: 5. Python爬虫入门五之URLError异常处理"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
