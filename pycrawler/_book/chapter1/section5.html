<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>5. Python爬虫入门五之URLError异常处理 | Python爬虫学习系列教程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../chapter1/section6.html" />
    
    
    <link rel="prev" href="../chapter1/section4.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="1.5"
        data-chapter-title="5. Python爬虫入门五之URLError异常处理"
        data-filepath="chapter1/section5.md"
        data-basepath=".."
        data-revision="Wed Jun 21 2017 19:16:14 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Python爬虫学习系列教程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="chapter1/index.html">
            
                
                    <a href="../chapter1/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        一、爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="chapter1/section1.html">
            
                
                    <a href="../chapter1/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        1. Python爬虫入门一之综述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="chapter1/section2.html">
            
                
                    <a href="../chapter1/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        2. Python爬虫入门二之爬虫基础了解
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="chapter1/section3.html">
            
                
                    <a href="../chapter1/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        3. Python爬虫入门三之Urllib库的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="chapter1/section4.html">
            
                
                    <a href="../chapter1/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                        4. Python爬虫入门四之Urllib库的高级用法
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="1.5" data-path="chapter1/section5.html">
            
                
                    <a href="../chapter1/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.5.</b>
                        
                        5. Python爬虫入门五之URLError异常处理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="chapter1/section6.html">
            
                
                    <a href="../chapter1/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.6.</b>
                        
                        6. Python爬虫入门六之Cookie的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="chapter1/section7.html">
            
                
                    <a href="../chapter1/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.7.</b>
                        
                        7. Python爬虫入门七之正则表达式
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="chapter2/index.html">
            
                
                    <a href="../chapter2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        二、爬虫实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="chapter2/section1.html">
            
                
                    <a href="../chapter2/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        1. Python爬虫实战一之爬取糗事百科段子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="chapter2/section2.html">
            
                
                    <a href="../chapter2/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        2. Python爬虫实战二之爬取百度贴吧帖子
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="chapter2/section3.html">
            
                
                    <a href="../chapter2/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        3. Python爬虫实战三之实现山东大学无线网络掉线自动重连
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="chapter2/section4.html">
            
                
                    <a href="../chapter2/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        4. Python爬虫实战四之抓取淘宝MM照片
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="chapter2/section5.html">
            
                
                    <a href="../chapter2/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.5.</b>
                        
                        5. Python爬虫实战五之模拟登录淘宝并获取所有订单
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="chapter2/section6.html">
            
                
                    <a href="../chapter2/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.6.</b>
                        
                        6. Python爬虫实战六之抓取爱问知识人问题并保存至数据库
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="chapter2/section7.html">
            
                
                    <a href="../chapter2/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.7.</b>
                        
                        7. Python爬虫实战七之计算大学本学期绩点
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="chapter2/section8.html">
            
                
                    <a href="../chapter2/section8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.8.</b>
                        
                        8. Python爬虫实战八之利用Selenium抓取淘宝匿名旺旺
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="chapter3/index.html">
            
                
                    <a href="../chapter3/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        三、爬虫利器
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="chapter3/section1.html">
            
                
                    <a href="../chapter3/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        1. Python爬虫利器一之Requests库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="chapter3/section2.html">
            
                
                    <a href="../chapter3/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        2. Python爬虫利器二之Beautiful Soup的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="chapter3/section3.html">
            
                
                    <a href="../chapter3/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        3. Python爬虫利器三之Xpath语法与lxml库的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="chapter3/section4.html">
            
                
                    <a href="../chapter3/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        4. Python爬虫利器四之PhantomJS的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="chapter3/section5.html">
            
                
                    <a href="../chapter3/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        5. Python爬虫利器五之Selenium的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="chapter3/section6.html">
            
                
                    <a href="../chapter3/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.6.</b>
                        
                        6. Python爬虫利器六之PyQuery的用法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="chapter4/index.html">
            
                
                    <a href="../chapter4/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        四、爬虫进阶
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="chapter4/section1.html">
            
                
                    <a href="../chapter4/section1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        1. Python爬虫进阶一之爬虫框架概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter4/section2.html">
            
                
                    <a href="../chapter4/section2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        2. Python爬虫进阶二之PySpider框架安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="chapter4/section3.html">
            
                
                    <a href="../chapter4/section3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        3. Python爬虫进阶三之爬虫框架Scrapy安装配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="chapter4/section4.html">
            
                
                    <a href="../chapter4/section4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        4. Python爬虫进阶四之PySpider的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="chapter4/section5.html">
            
                
                    <a href="../chapter4/section5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        5. Python爬虫进阶五之多线程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="chapter4/section6.html">
            
                
                    <a href="../chapter4/section6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.6.</b>
                        
                        6. Python爬虫进阶六之多进程的用法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="chapter4/section7.html">
            
                
                    <a href="../chapter4/section7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.7.</b>
                        
                        7. Python爬虫进阶七之设置ADSL拨号服务器代理
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Python爬虫学习系列教程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="python&#x722C;&#x866B;&#x5165;&#x95E8;&#x4E94;&#x4E4B;urlerror&#x5F02;&#x5E38;&#x5904;&#x7406;">Python&#x722C;&#x866B;&#x5165;&#x95E8;&#x4E94;&#x4E4B;URLError&#x5F02;&#x5E38;&#x5904;&#x7406;</h1>
<p>&#x5927;&#x5BB6;&#x597D;&#xFF0C;&#x672C;&#x8282;&#x5728;&#x8FD9;&#x91CC;&#x4E3B;&#x8981;&#x8BF4;&#x7684;&#x662F;URLError&#x8FD8;&#x6709;HTTPError&#xFF0C;&#x4EE5;&#x53CA;&#x5BF9;&#x5B83;&#x4EEC;&#x7684;&#x4E00;&#x4E9B;&#x5904;&#x7406;&#x3002;</p>
<h2 id="1urlerror">1.URLError</h2>
<p>&#x9996;&#x5148;&#x89E3;&#x91CA;&#x4E0B;URLError&#x53EF;&#x80FD;&#x4EA7;&#x751F;&#x7684;&#x539F;&#x56E0;&#xFF1A;</p>
<ul>
<li>&#x7F51;&#x7EDC;&#x65E0;&#x8FDE;&#x63A5;&#xFF0C;&#x5373;&#x672C;&#x673A;&#x65E0;&#x6CD5;&#x4E0A;&#x7F51;</li>
<li>&#x8FDE;&#x63A5;&#x4E0D;&#x5230;&#x7279;&#x5B9A;&#x7684;&#x670D;&#x52A1;&#x5668;</li>
<li>&#x670D;&#x52A1;&#x5668;&#x4E0D;&#x5B58;&#x5728;</li>
</ul>
<p>&#x5728;&#x4EE3;&#x7801;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x7528;try-except&#x8BED;&#x53E5;&#x6765;&#x5305;&#x56F4;&#x5E76;&#x6355;&#x83B7;&#x76F8;&#x5E94;&#x7684;&#x5F02;&#x5E38;&#x3002;&#x4E0B;&#x9762;&#x662F;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#xFF0C;&#x5148;&#x611F;&#x53D7;&#x4E0B;&#x5B83;&#x7684;&#x98CE;&#x9A9A;</p>
<pre><code>import urllib2

requset = urllib2.Request(&apos;http://www.xxxxx.com&apos;)
try:
    urllib2.urlopen(request)
except urllib2.URLError, e:
    print e.reason
</code></pre><p>&#x6211;&#x4EEC;&#x5229;&#x7528;&#x4E86; urlopen&#x65B9;&#x6CD5;&#x8BBF;&#x95EE;&#x4E86;&#x4E00;&#x4E2A;&#x4E0D;&#x5B58;&#x5728;&#x7684;&#x7F51;&#x5740;&#xFF0C;&#x8FD0;&#x884C;&#x7ED3;&#x679C;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre><code>[Errno 11004] getaddrinfo failed
</code></pre><p>&#x5B83;&#x8BF4;&#x660E;&#x4E86;&#x9519;&#x8BEF;&#x4EE3;&#x53F7;&#x662F;11004&#xFF0C;&#x9519;&#x8BEF;&#x539F;&#x56E0;&#x662F; getaddrinfo failed</p>
<h2 id="2httperror">2.HTTPError</h2>
<p>HTTPError&#x662F;URLError&#x7684;&#x5B50;&#x7C7B;&#xFF0C;&#x5728;&#x4F60;&#x5229;&#x7528;urlopen&#x65B9;&#x6CD5;&#x53D1;&#x51FA;&#x4E00;&#x4E2A;&#x8BF7;&#x6C42;&#x65F6;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x4E0A;&#x90FD;&#x4F1A;&#x5BF9;&#x5E94;&#x4E00;&#x4E2A;&#x5E94;&#x7B54;&#x5BF9;&#x8C61;response&#xFF0C;&#x5176;&#x4E2D;&#x5B83;&#x5305;&#x542B;&#x4E00;&#x4E2A;&#x6570;&#x5B57;&#x201D;&#x72B6;&#x6001;&#x7801;&#x201D;&#x3002;&#x4E3E;&#x4E2A;&#x4F8B;&#x5B50;&#xFF0C;&#x5047;&#x5982;response&#x662F;&#x4E00;&#x4E2A;&#x201D;&#x91CD;&#x5B9A;&#x5411;&#x201D;&#xFF0C;&#x9700;&#x5B9A;&#x4F4D;&#x5230;&#x522B;&#x7684;&#x5730;&#x5740;&#x83B7;&#x53D6;&#x6587;&#x6863;&#xFF0C;urllib2&#x5C06;&#x5BF9;&#x6B64;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x3002;</p>
<p>&#x5176;&#x4ED6;&#x4E0D;&#x80FD;&#x5904;&#x7406;&#x7684;&#xFF0C;urlopen&#x4F1A;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;HTTPError&#xFF0C;&#x5BF9;&#x5E94;&#x76F8;&#x5E94;&#x7684;&#x72B6;&#x6001;&#x5417;&#xFF0C;HTTP&#x72B6;&#x6001;&#x7801;&#x8868;&#x793A;HTTP&#x534F;&#x8BAE;&#x6240;&#x8FD4;&#x56DE;&#x7684;&#x54CD;&#x5E94;&#x7684;&#x72B6;&#x6001;&#x3002;&#x4E0B;&#x9762;&#x5C06;&#x72B6;&#x6001;&#x7801;&#x5F52;&#x7ED3;&#x5982;&#x4E0B;&#xFF1A;</p>
<blockquote>
<ul>
<li>100&#xFF1A;&#x7EE7;&#x7EED;  &#x5BA2;&#x6237;&#x7AEF;&#x5E94;&#x5F53;&#x7EE7;&#x7EED;&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x3002;&#x5BA2;&#x6237;&#x7AEF;&#x5E94;&#x5F53;&#x7EE7;&#x7EED;&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x7684;&#x5269;&#x4F59;&#x90E8;&#x5206;&#xFF0C;&#x6216;&#x8005;&#x5982;&#x679C;&#x8BF7;&#x6C42;&#x5DF2;&#x7ECF;&#x5B8C;&#x6210;&#xFF0C;&#x5FFD;&#x7565;&#x8FD9;&#x4E2A;&#x54CD;&#x5E94;&#x3002;</li>
<li>101&#xFF1A; &#x8F6C;&#x6362;&#x534F;&#x8BAE;  &#x5728;&#x53D1;&#x9001;&#x5B8C;&#x8FD9;&#x4E2A;&#x54CD;&#x5E94;&#x6700;&#x540E;&#x7684;&#x7A7A;&#x884C;&#x540E;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x5C06;&#x4F1A;&#x5207;&#x6362;&#x5230;&#x5728;Upgrade &#x6D88;&#x606F;&#x5934;&#x4E2D;&#x5B9A;&#x4E49;&#x7684;&#x90A3;&#x4E9B;&#x534F;&#x8BAE;&#x3002;&#x53EA;&#x6709;&#x5728;&#x5207;&#x6362;&#x65B0;&#x7684;&#x534F;&#x8BAE;&#x66F4;&#x6709;&#x597D;&#x5904;&#x7684;&#x65F6;&#x5019;&#x624D;&#x5E94;&#x8BE5;&#x91C7;&#x53D6;&#x7C7B;&#x4F3C;&#x63AA;&#x65BD;&#x3002;</li>
<li>102&#xFF1A;&#x7EE7;&#x7EED;&#x5904;&#x7406;   &#x7531;WebDAV&#xFF08;RFC 2518&#xFF09;&#x6269;&#x5C55;&#x7684;&#x72B6;&#x6001;&#x7801;&#xFF0C;&#x4EE3;&#x8868;&#x5904;&#x7406;&#x5C06;&#x88AB;&#x7EE7;&#x7EED;&#x6267;&#x884C;&#x3002;</li>
<li>200&#xFF1A;&#x8BF7;&#x6C42;&#x6210;&#x529F;      &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x83B7;&#x5F97;&#x54CD;&#x5E94;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x8FDB;&#x884C;&#x5904;&#x7406;</li>
<li>201&#xFF1A;&#x8BF7;&#x6C42;&#x5B8C;&#x6210;&#xFF0C;&#x7ED3;&#x679C;&#x662F;&#x521B;&#x5EFA;&#x4E86;&#x65B0;&#x8D44;&#x6E90;&#x3002;&#x65B0;&#x521B;&#x5EFA;&#x8D44;&#x6E90;&#x7684;URI&#x53EF;&#x5728;&#x54CD;&#x5E94;&#x7684;&#x5B9E;&#x4F53;&#x4E2D;&#x5F97;&#x5230;    &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x722C;&#x866B;&#x4E2D;&#x4E0D;&#x4F1A;&#x9047;&#x5230;</li>
<li>202&#xFF1A;&#x8BF7;&#x6C42;&#x88AB;&#x63A5;&#x53D7;&#xFF0C;&#x4F46;&#x5904;&#x7406;&#x5C1A;&#x672A;&#x5B8C;&#x6210;    &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x963B;&#x585E;&#x7B49;&#x5F85;</li>
<li>204&#xFF1A;&#x670D;&#x52A1;&#x5668;&#x7AEF;&#x5DF2;&#x7ECF;&#x5B9E;&#x73B0;&#x4E86;&#x8BF7;&#x6C42;&#xFF0C;&#x4F46;&#x662F;&#x6CA1;&#x6709;&#x8FD4;&#x56DE;&#x65B0;&#x7684;&#x4FE1; &#x606F;&#x3002;&#x5982;&#x679C;&#x5BA2;&#x6237;&#x662F;&#x7528;&#x6237;&#x4EE3;&#x7406;&#xFF0C;&#x5219;&#x65E0;&#x987B;&#x4E3A;&#x6B64;&#x66F4;&#x65B0;&#x81EA;&#x8EAB;&#x7684;&#x6587;&#x6863;&#x89C6;&#x56FE;&#x3002;    &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x4E22;&#x5F03;</li>
<li>300&#xFF1A;&#x8BE5;&#x72B6;&#x6001;&#x7801;&#x4E0D;&#x88AB;HTTP/1.0&#x7684;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x76F4;&#x63A5;&#x4F7F;&#x7528;&#xFF0C; &#x53EA;&#x662F;&#x4F5C;&#x4E3A;3XX&#x7C7B;&#x578B;&#x56DE;&#x5E94;&#x7684;&#x9ED8;&#x8BA4;&#x89E3;&#x91CA;&#x3002;&#x5B58;&#x5728;&#x591A;&#x4E2A;&#x53EF;&#x7528;&#x7684;&#x88AB;&#x8BF7;&#x6C42;&#x8D44;&#x6E90;&#x3002;    &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x82E5;&#x7A0B;&#x5E8F;&#x4E2D;&#x80FD;&#x591F;&#x5904;&#x7406;&#xFF0C;&#x5219;&#x8FDB;&#x884C;&#x8FDB;&#x4E00;&#x6B65;&#x5904;&#x7406;&#xFF0C;&#x5982;&#x679C;&#x7A0B;&#x5E8F;&#x4E2D;&#x4E0D;&#x80FD;&#x5904;&#x7406;&#xFF0C;&#x5219;&#x4E22;&#x5F03;</li>
<li>301&#xFF1A;&#x8BF7;&#x6C42;&#x5230;&#x7684;&#x8D44;&#x6E90;&#x90FD;&#x4F1A;&#x5206;&#x914D;&#x4E00;&#x4E2A;&#x6C38;&#x4E45;&#x7684;URL&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x53EF;&#x4EE5;&#x5728;&#x5C06;&#x6765;&#x901A;&#x8FC7;&#x8BE5;URL&#x6765;&#x8BBF;&#x95EE;&#x6B64;&#x8D44;&#x6E90;    &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x91CD;&#x5B9A;&#x5411;&#x5230;&#x5206;&#x914D;&#x7684;URL</li>
<li>302&#xFF1A;&#x8BF7;&#x6C42;&#x5230;&#x7684;&#x8D44;&#x6E90;&#x5728;&#x4E00;&#x4E2A;&#x4E0D;&#x540C;&#x7684;URL&#x5904;&#x4E34;&#x65F6;&#x4FDD;&#x5B58;     &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x91CD;&#x5B9A;&#x5411;&#x5230;&#x4E34;&#x65F6;&#x7684;URL</li>
<li>304&#xFF1A;&#x8BF7;&#x6C42;&#x7684;&#x8D44;&#x6E90;&#x672A;&#x66F4;&#x65B0;     &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x4E22;&#x5F03;</li>
<li>400&#xFF1A;&#x975E;&#x6CD5;&#x8BF7;&#x6C42;     &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x4E22;&#x5F03;</li>
<li>401&#xFF1A;&#x672A;&#x6388;&#x6743;     &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x4E22;&#x5F03;</li>
<li>403&#xFF1A;&#x7981;&#x6B62;     &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x4E22;&#x5F03;</li>
<li>404&#xFF1A;&#x6CA1;&#x6709;&#x627E;&#x5230;     &#x5904;&#x7406;&#x65B9;&#x5F0F;&#xFF1A;&#x4E22;&#x5F03;</li>
<li>500&#xFF1A;&#x670D;&#x52A1;&#x5668;&#x5185;&#x90E8;&#x9519;&#x8BEF;  &#x670D;&#x52A1;&#x5668;&#x9047;&#x5230;&#x4E86;&#x4E00;&#x4E2A;&#x672A;&#x66FE;&#x9884;&#x6599;&#x7684;&#x72B6;&#x51B5;&#xFF0C;&#x5BFC;&#x81F4;&#x4E86;&#x5B83;&#x65E0;&#x6CD5;&#x5B8C;&#x6210;&#x5BF9;&#x8BF7;&#x6C42;&#x7684;&#x5904;&#x7406;&#x3002;&#x4E00;&#x822C;&#x6765;&#x8BF4;&#xFF0C;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x90FD;&#x4F1A;&#x5728;&#x670D;&#x52A1;&#x5668;&#x7AEF;&#x7684;&#x6E90;&#x4EE3;&#x7801;&#x51FA;&#x73B0;&#x9519;&#x8BEF;&#x65F6;&#x51FA;&#x73B0;&#x3002;</li>
<li>501&#xFF1A;&#x670D;&#x52A1;&#x5668;&#x65E0;&#x6CD5;&#x8BC6;&#x522B;  &#x670D;&#x52A1;&#x5668;&#x4E0D;&#x652F;&#x6301;&#x5F53;&#x524D;&#x8BF7;&#x6C42;&#x6240;&#x9700;&#x8981;&#x7684;&#x67D0;&#x4E2A;&#x529F;&#x80FD;&#x3002;&#x5F53;&#x670D;&#x52A1;&#x5668;&#x65E0;&#x6CD5;&#x8BC6;&#x522B;&#x8BF7;&#x6C42;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5E76;&#x4E14;&#x65E0;&#x6CD5;&#x652F;&#x6301;&#x5176;&#x5BF9;&#x4EFB;&#x4F55;&#x8D44;&#x6E90;&#x7684;&#x8BF7;&#x6C42;&#x3002;</li>
<li>502&#xFF1A;&#x9519;&#x8BEF;&#x7F51;&#x5173;  &#x4F5C;&#x4E3A;&#x7F51;&#x5173;&#x6216;&#x8005;&#x4EE3;&#x7406;&#x5DE5;&#x4F5C;&#x7684;&#x670D;&#x52A1;&#x5668;&#x5C1D;&#x8BD5;&#x6267;&#x884C;&#x8BF7;&#x6C42;&#x65F6;&#xFF0C;&#x4ECE;&#x4E0A;&#x6E38;&#x670D;&#x52A1;&#x5668;&#x63A5;&#x6536;&#x5230;&#x65E0;&#x6548;&#x7684;&#x54CD;&#x5E94;&#x3002;</li>
<li>503&#xFF1A;&#x670D;&#x52A1;&#x51FA;&#x9519;   &#x7531;&#x4E8E;&#x4E34;&#x65F6;&#x7684;&#x670D;&#x52A1;&#x5668;&#x7EF4;&#x62A4;&#x6216;&#x8005;&#x8FC7;&#x8F7D;&#xFF0C;&#x670D;&#x52A1;&#x5668;&#x5F53;&#x524D;&#x65E0;&#x6CD5;&#x5904;&#x7406;&#x8BF7;&#x6C42;&#x3002;&#x8FD9;&#x4E2A;&#x72B6;&#x51B5;&#x662F;&#x4E34;&#x65F6;&#x7684;&#xFF0C;&#x5E76;&#x4E14;&#x5C06;&#x5728;&#x4E00;&#x6BB5;&#x65F6;&#x95F4;&#x4EE5;&#x540E;&#x6062;&#x590D;&#x3002;</li>
</ul>
</blockquote>
<p>HTTPError&#x5B9E;&#x4F8B;&#x4EA7;&#x751F;&#x540E;&#x4F1A;&#x6709;&#x4E00;&#x4E2A;code&#x5C5E;&#x6027;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;&#x662F;&#x670D;&#x52A1;&#x5668;&#x53D1;&#x9001;&#x7684;&#x76F8;&#x5173;&#x9519;&#x8BEF;&#x53F7;&#x3002;
&#x56E0;&#x4E3A;urllib2&#x53EF;&#x4EE5;&#x4E3A;&#x4F60;&#x5904;&#x7406;&#x91CD;&#x5B9A;&#x5411;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;3&#x5F00;&#x5934;&#x7684;&#x4EE3;&#x53F7;&#x53EF;&#x4EE5;&#x88AB;&#x5904;&#x7406;&#xFF0C;&#x5E76;&#x4E14;100-299&#x8303;&#x56F4;&#x7684;&#x53F7;&#x7801;&#x6307;&#x793A;&#x6210;&#x529F;&#xFF0C;&#x6240;&#x4EE5;&#x4F60;&#x53EA;&#x80FD;&#x770B;&#x5230;400-599&#x7684;&#x9519;&#x8BEF;&#x53F7;&#x7801;&#x3002;</p>
<p>&#x4E0B;&#x9762;&#x6211;&#x4EEC;&#x5199;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#x6765;&#x611F;&#x53D7;&#x4E00;&#x4E0B;&#xFF0C;&#x6355;&#x83B7;&#x7684;&#x5F02;&#x5E38;&#x662F;HTTPError&#xFF0C;&#x5B83;&#x4F1A;&#x5E26;&#x6709;&#x4E00;&#x4E2A;code&#x5C5E;&#x6027;&#xFF0C;&#x5C31;&#x662F;&#x9519;&#x8BEF;&#x4EE3;&#x53F7;&#xFF0C;&#x53E6;&#x5916;&#x6211;&#x4EEC;&#x53C8;&#x6253;&#x5370;&#x4E86;reason&#x5C5E;&#x6027;&#xFF0C;&#x8FD9;&#x662F;&#x5B83;&#x7684;&#x7236;&#x7C7B;URLError&#x7684;&#x5C5E;&#x6027;&#x3002;</p>
<pre><code>import urllib2

req = urllib2.Request(&apos;http://blog.csdn.net/cqcre&apos;)
try:
    urllib2.urlopen(req)
except urllib2.HTTPError, e:
    print e.code
    print e.reason
</code></pre><p>&#x8FD0;&#x884C;&#x7ED3;&#x679C;&#x5982;&#x4E0B;</p>
<pre><code>403
Forbidden
</code></pre><p>&#x9519;&#x8BEF;&#x4EE3;&#x53F7;&#x662F;403&#xFF0C;&#x9519;&#x8BEF;&#x539F;&#x56E0;&#x662F;Forbidden&#xFF0C;&#x8BF4;&#x660E;&#x670D;&#x52A1;&#x5668;&#x7981;&#x6B62;&#x8BBF;&#x95EE;&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x77E5;&#x9053;&#xFF0C;HTTPError&#x7684;&#x7236;&#x7C7B;&#x662F;URLError&#xFF0C;&#x6839;&#x636E;&#x7F16;&#x7A0B;&#x7ECF;&#x9A8C;&#xFF0C;&#x7236;&#x7C7B;&#x7684;&#x5F02;&#x5E38;&#x5E94;&#x5F53;&#x5199;&#x5230;&#x5B50;&#x7C7B;&#x5F02;&#x5E38;&#x7684;&#x540E;&#x9762;&#xFF0C;&#x5982;&#x679C;&#x5B50;&#x7C7B;&#x6355;&#x83B7;&#x4E0D;&#x5230;&#xFF0C;&#x90A3;&#x4E48;&#x53EF;&#x4EE5;&#x6355;&#x83B7;&#x7236;&#x7C7B;&#x7684;&#x5F02;&#x5E38;&#xFF0C;&#x6240;&#x4EE5;&#x4E0A;&#x8FF0;&#x7684;&#x4EE3;&#x7801;&#x53EF;&#x4EE5;&#x8FD9;&#x4E48;&#x6539;&#x5199;</p>
<pre><code>import urllib2

req = urllib2.Request(&apos;http://blog.csdn.net/cqcre&apos;)
try:
    urllib2.urlopen(req)
except urllib2.HTTPError, e:
    print e.code
except urllib2.URLError, e:
    print e.reason
else:
    print &quot;OK&quot;
</code></pre><p>&#x5982;&#x679C;&#x6355;&#x83B7;&#x5230;&#x4E86;HTTPError&#xFF0C;&#x5219;&#x8F93;&#x51FA;code&#xFF0C;&#x4E0D;&#x4F1A;&#x518D;&#x5904;&#x7406;URLError&#x5F02;&#x5E38;&#x3002;&#x5982;&#x679C;&#x53D1;&#x751F;&#x7684;&#x4E0D;&#x662F;HTTPError&#xFF0C;&#x5219;&#x4F1A;&#x53BB;&#x6355;&#x83B7;URLError&#x5F02;&#x5E38;&#xFF0C;&#x8F93;&#x51FA;&#x9519;&#x8BEF;&#x539F;&#x56E0;&#x3002;</p>
<p>&#x53E6;&#x5916;&#x8FD8;&#x53EF;&#x4EE5;&#x52A0;&#x5165; hasattr&#x5C5E;&#x6027;&#x63D0;&#x524D;&#x5BF9;&#x5C5E;&#x6027;&#x8FDB;&#x884C;&#x5224;&#x65AD;&#xFF0C;&#x4EE3;&#x7801;&#x6539;&#x5199;&#x5982;&#x4E0B;</p>
<pre><code>import urllib2

req = urllib2.Request(&apos;http://blog.csdn.net/cqcre&apos;)
try:
    urllib2.urlopen(req)
except urllib2.URLError, e:
    if hasattr(e,&quot;reason&quot;):
        print e.reason
else:
    print &quot;OK&quot;
</code></pre><p>&#x9996;&#x5148;&#x5BF9;&#x5F02;&#x5E38;&#x7684;&#x5C5E;&#x6027;&#x8FDB;&#x884C;&#x5224;&#x65AD;&#xFF0C;&#x4EE5;&#x514D;&#x51FA;&#x73B0;&#x5C5E;&#x6027;&#x8F93;&#x51FA;&#x62A5;&#x9519;&#x7684;&#x73B0;&#x8C61;&#x3002;</p>
<p>&#x4EE5;&#x4E0A;&#xFF0C;&#x5C31;&#x662F;&#x5BF9;URLError&#x548C;HTTPError&#x7684;&#x76F8;&#x5173;&#x4ECB;&#x7ECD;&#xFF0C;&#x4EE5;&#x53CA;&#x76F8;&#x5E94;&#x7684;&#x9519;&#x8BEF;&#x5904;&#x7406;&#x529E;&#x6CD5;&#xFF0C;&#x5C0F;&#x4F19;&#x4F34;&#x4EEC;&#x52A0;&#x6CB9;&#xFF01;</p>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../chapter1/section4.html" class="navigation navigation-prev " aria-label="Previous page: 4. Python爬虫入门四之Urllib库的高级用法"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../chapter1/section6.html" class="navigation navigation-next " aria-label="Next page: 6. Python爬虫入门六之Cookie的使用"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
